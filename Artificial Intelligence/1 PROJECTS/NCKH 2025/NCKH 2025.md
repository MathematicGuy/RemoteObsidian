**Dự án: "Nghiên cứu và xây dựng mô-đun nhận diện hành vi của
sinh viên trong giảng đường"**

- **Mô tả:** Phát triển một hệ thống phân loại các hành vi bất thường đơn giản (ví dụ: chạy quá nhanh, leo trèo, tụ tập) trong video giám sát.
    
- **Dataset:**
    
    - **UCF-Crime:** Mặc dù dataset này chủ yếu về các hành vi tội phạm, một số hành vi (ví dụ: chạy, xô đẩy) có thể tương tự với hành vi bất thường trong trường học. Bạn có thể chọn lọc các video phù hợp.
        
    - **Real Life Violence Situations Dataset:** Dataset này có các video về hành vi bạo lực nhưng cũng có các hành vi khác như xô đẩy, tụ tập mà có thể sử dụng cho bài toán này.
        
    - **Tự thu thập:** Bạn có thể tự thu thập các video về các hành vi này từ YouTube hoặc các nguồn khác.
    
+ Note:
	Optimizer: PSO ([Particle swarm optimization](https://en.wikipedia.org/wiki/Particle_swarm_optimization))
	

---

**References:**
+ [LSTM](https://phamdinhkhanh.github.io/2019/04/22/Ly_thuyet_ve_mang_LSTM.html)
+ [Human Pose Detection using LSTM](https://nam157.github.io/human_activity_recognition-/)
+ [[Pose Estimation Note]]
+ [[Human Activity Recognition Methods using RNN + LSTM]]

---

```python
"""
    Input: skeletons = {bodyi {j : (xjoint_j , yjoint_j ), j = [0, 17]}, i = [0, n −1]}
    boxes_object = {boxi (x1, y1, x2, y2 ), i = [0, m −1]}
    n: number of skeletons
    m: number of bounding boxes
    
    Output: boxes_skeleton = {boxi (x1, y1, x2, y2 ), i = [0, n −1]}
    boxes_all = {boxj (x1, y1, x2, y2 ), j = [0, k −1]}
    k: number of persons
"""

for body in skeletons:
    x1 = min(xbody )
    y1 = min(ybody )
    x2 = max(xbody )
    y2 = max(ybody )
    boxes_skeleton.append(x1, y1, x2, y2 )
    boxes_all = boxes_skeleton

    status_skeletons = [True for (i, item) in enumerate(skeletons)]

    for (index_box, box) in enumerate(boxes_object):
        index_max = -1
        number_joints = 0

        for (index_body, body) in enumerate(skeletons):
            if not(status_skeletons[index_body]):
                continue
            if number_joints < count_points(box, body):
                number_joints = count_points(box, body)
                index_max = index_body

    if index_max == -1:
        boxes_append(box)
    else:
        
        status_skeletons[index_max] = False
        boxes_skeleton[index_max] = box
        boxes_all[index_max] = box
return boxes_skeleton, boxes_all
```

---

**Requirements:** Kế hoạch thực hiện bám sát theo chủ đề đề tài NCKH. Có thể thiếu nhưng không thể thêm. $$N(y_{i}; b) = \frac{y_{i} - b}{(b_{w}, b_{h})}$$ where $y_{i}$ are the coordinate of the n joint (e.g. ankle)

*Solve Pose Estimation as Regression problems*

MSE (Loss)
![[Pasted image 20250115060102.png]]

**Pose Estimation as DNN-based Regressor** to detect and locating position of every single joints. 
![[Pasted image 20250115060225.png]]
-> Detect current pose base on joints locations. 
**Cascade of Pose Regressors** -> Learn features of the current pose
All we care about is the location of the joints.  

---
### Plan
[[Student Behavior Recognition System Planning]]
[[Human Pose Detection Planning (Behaviour Detection)]]

----
### MediaPipe (Low Computation + Highly Customizable)
**2 step Detector:** Detection + Tracking 
![[Pasted image 20250115163509.png]]

**Methods & Performances**
![[Pasted image 20250115170650.png]]

**Pose Detection in Images and on Videos**
