If you have a super powerful memory , your model can remember and understand the property of your loss function landscape and find a effective solution to that.

associative memory - the ability to map and recall one thing based on another (like recalling a name when you see a face).

We show that the **training process itself,** specifically the [backpropagation](https://en.wikipedia.org/wiki/Backpropagation) process, can be **modeled as an associative memory**

---
## [[Continuous Learning & Nested Learning Survey]]

## [[Deepfake Survey]]
-> Detect Deepfake by detect anomaly (too good to be true color scheme) Image Frequency. 

**Class Imbalance Handling**
The dataset comprises a total of **262,160 images, with 42,690 labeled as real and 219,470 labeled as fake**, resulting in a significant class imbalance. To address this imbalance, **In each epoch we use 25600 images**, with a **batch size of 256** where **half of the images are taken randomly from the real data set** and the **other half is taken randomly the fake data set**. We repeat this process for each epoc

---

**Mediapipe + Feature Engineer + LSTM approach for Action Recognition Problem** 
