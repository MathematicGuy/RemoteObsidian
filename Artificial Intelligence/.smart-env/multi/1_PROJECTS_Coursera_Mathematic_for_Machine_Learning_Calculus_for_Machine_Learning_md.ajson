
"smart_sources:1 PROJECTS/Coursera Mathematic for Machine Learning/Calculus for Machine Learning.md": {"path":"1 PROJECTS/Coursera Mathematic for Machine Learning/Calculus for Machine Learning.md","last_embed":{"hash":null},"embeddings":{},"last_read":{"hash":"1rm3y42","at":1768089397381},"class_name":"SmartSource","last_import":{"mtime":1759329344451,"size":872,"at":1768089397381,"hash":"1rm3y42"},"blocks":{"#Week 1: Derivatives and Optimization":[1,24],"#Week 1: Derivatives and Optimization#{1}":[2,6],"#Week 1: Derivatives and Optimization#[[Calculus_Derivative]]":[7,7],"#Week 1: Derivatives and Optimization#[[Calculus_Optimization]]":[8,10],"#Week 1: Derivatives and Optimization#[[Calculus_Optimization]]#{1}":[9,10],"#Week 1: Derivatives and Optimization#Week 2: Gradient and Gradient Descent":[11,13],"#Week 1: Derivatives and Optimization#Week 2: Gradient and Gradient Descent#{1}":[12,13],"#Week 1: Derivatives and Optimization#[[Gradient and Gradient Descent]]":[14,16],"#Week 1: Derivatives and Optimization#[[Gradient and Gradient Descent]]#{1}":[15,16],"#Week 1: Derivatives and Optimization#[[Week 3 - Optimization in Neural Network and Newton's Method]]":[17,24],"#Week 1: Derivatives and Optimization#[[Week 3 - Optimization in Neural Network and Newton's Method]]#[[Lesson 1 - Optimization in Neural Network]]":[19,19],"#Week 1: Derivatives and Optimization#[[Week 3 - Optimization in Neural Network and Newton's Method]]#[[Lesson 2 - Newton's Method]]":[20,24],"#Week 1: Derivatives and Optimization#[[Week 3 - Optimization in Neural Network and Newton's Method]]#[[Lesson 2 - Newton's Method]]#{1}":[21,24]},"outlinks":[{"title":"Calculus_Derivative","target":"Calculus_Derivative","line":7},{"title":"Calculus_Optimization","target":"Calculus_Optimization","line":8},{"title":"Derivative and Optimization Test","target":"Derivative and Optimization Test","line":9},{"title":"Gradient and Gradient Descent","target":"Gradient and Gradient Descent","line":14},{"title":"Linear Regression Using Gradient Descent Exercise","target":"Linear Regression Using Gradient Descent Exercise","line":15},{"title":"Week 3 - Optimization in Neural Network and Newton's Method","target":"Week 3 - Optimization in Neural Network and Newton's Method","line":17},{"title":"Lesson 1 - Optimization in Neural Network","target":"Lesson 1 - Optimization in Neural Network","line":19},{"title":"Lesson 2 - Newton's Method","target":"Lesson 2 - Newton's Method","line":20},{"title":"Optimization in Neural Networks and Newton's Method","target":"Optimization in Neural Networks and Newton's Method","line":21},{"title":"Optimization in Neural Network and Newton's Method Final Test","target":"Optimization in Neural Network and Newton's Method Final Test","line":22}],"task_lines":[],"tasks":{},"codeblock_ranges":[[3,6]]},
"smart_sources:1 PROJECTS/Coursera Mathematic for Machine Learning/Calculus for Machine Learning.md": {"path":"1 PROJECTS/Coursera Mathematic for Machine Learning/Calculus for Machine Learning.md","embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.05172179,-0.01784105,0.0240378,-0.0224657,0.00852591,-0.00624601,-0.03479322,0.09714239,0.05809449,-0.01032114,0.04343962,-0.04476227,0.03631137,0.03542666,0.03673765,-0.01196781,0.01302129,0.07845981,-0.06808851,-0.04619333,0.10684792,-0.02343794,-0.0668993,-0.11322461,0.05434662,-0.06972989,-0.02244168,0.0248459,-0.00879839,-0.21203141,0.02554353,-0.03723669,0.03879501,-0.07129599,0.00080761,0.03414973,-0.01101099,0.00933181,-0.08263756,0.02686431,-0.01498717,0.03824931,-0.04184667,-0.03114101,0.0046657,-0.05469435,0.00313577,-0.04094794,-0.02771809,0.01277243,-0.00784185,0.01197532,0.03490781,-0.01902736,0.00351208,0.01056,0.07370678,0.06132331,0.01010502,0.05322957,0.01375472,0.04878944,-0.20369686,0.07374656,-0.02224346,0.04785609,0.01537118,-0.04509494,0.02598779,0.1448192,-0.01300538,0.04447471,0.01021653,0.02905593,0.01334235,0.0275656,0.03773017,-0.03264796,-0.02057451,-0.00047375,0.00614037,0.00394564,-0.06003259,-0.05466046,0.06862688,-0.03926716,-0.0068137,0.00103139,0.03022509,-0.01087041,0.04420937,-0.02484019,-0.02669728,-0.02147902,-0.01282444,0.05687926,0.05135374,-0.00741892,-0.07371169,0.10430398,-0.04289781,0.01751909,-0.01224728,-0.01818261,0.00051674,0.01106146,-0.01804047,-0.03067139,0.02011679,-0.07520034,-0.03993623,-0.00577514,0.00252353,-0.01040446,-0.05778299,0.01777459,-0.00271616,0.02532496,-0.00775642,-0.00050486,-0.03471902,0.0110001,0.08113149,0.01339034,0.03411252,-0.0374295,-0.03677849,0.06904306,-0.007938,0.02815861,0.06024361,0.00671577,-0.00021365,-0.01466912,0.05636365,0.01466786,0.0017936,-0.0133929,-0.00017516,0.02558802,-0.03836401,0.02370064,0.02488698,-0.08373379,-0.08296472,0.1317265,-0.03568998,-0.0263995,-0.02559881,-0.06932849,0.05035735,0.0245258,-0.04572348,-0.00711287,0.03356249,0.05403831,0.08187232,-0.01774848,-0.14268954,-0.0111661,-0.06448124,0.01272388,-0.00220923,0.15759133,-0.00062036,0.00066399,0.0378926,-0.00327595,-0.00306062,-0.01572109,0.11267135,0.03499392,-0.04179513,-0.00502319,0.03852525,-0.00007679,-0.05457611,0.02095605,-0.06166882,0.04903765,0.00478152,-0.05561442,-0.02059401,-0.01130886,0.04521249,0.00834796,0.01273638,-0.04810135,-0.0081331,0.02505084,-0.04731786,0.00672198,-0.00863742,-0.04035657,-0.05238545,-0.06727107,0.01805575,-0.01158445,-0.03076277,0.00798429,-0.00245898,-0.00447944,0.02428135,0.01999296,-0.03847676,-0.00391374,0.05111619,-0.06271342,0.05405835,0.02482647,-0.03615379,-0.04717699,0.07462841,-0.06476066,-0.0222282,0.02307973,0.04152171,-0.00749228,-0.06510632,0.05645658,0.01867992,0.06338593,-0.06215634,-0.16513194,-0.08725764,0.02380981,-0.00319493,0.04505594,-0.07070481,0.07124107,-0.01039565,0.01397964,0.08401354,0.07183413,0.01194289,-0.04304112,-0.02599455,-0.01483923,-0.04006449,0.00306727,0.00911641,-0.02585777,-0.0163782,0.01323703,-0.00659168,0.05915951,-0.11352119,-0.01932409,-0.0202507,0.14126609,-0.02150005,0.092773,-0.01860102,-0.01675026,-0.04627828,0.01127986,-0.01795402,0.00229028,-0.04311306,0.0189834,-0.05849721,-0.00186611,-0.02720744,-0.00423677,0.04402259,0.01288298,-0.05999555,-0.11614431,-0.03650854,-0.01923347,0.02053354,-0.04419225,0.09410222,0.0095902,0.00790789,0.03545321,-0.05145964,0.04176462,-0.04424674,-0.05314264,-0.01533386,-0.03861094,0.0193965,0.03537896,-0.07537685,0.02001318,-0.04178625,0.05666041,-0.04459679,0.03922622,-0.03194819,-0.00031327,0.01713271,0.0108115,0.09823266,0.04958009,0.02876496,0.04908851,-0.00984792,0.05274019,0.0060898,-0.04717642,-0.02424766,0.04348748,-0.03492486,0.06970498,-0.02308221,0.02197635,-0.00843176,0.09535766,-0.07926253,0.02072681,0.03563434,-0.07996212,-0.03864631,-0.01327241,0.0108023,0.08085525,-0.009878,-0.21575391,0.00949897,0.0360465,-0.03564287,0.03638708,-0.01091485,0.10866176,-0.06217344,-0.08943257,0.00650337,-0.03700555,0.05088363,0.02983942,-0.01844366,0.04146793,0.00027828,0.04694321,0.0039114,0.05017586,-0.03084523,0.02394426,0.07358319,0.16684492,-0.10056467,0.02982747,0.0269716,-0.03195019,-0.01138769,0.07013427,-0.04569684,0.02303425,0.03934735,0.05295784,-0.07488303,-0.00304243,0.13960966,-0.03518903,0.02021272,0.09308392,0.04188265,0.06009893,0.00751994,-0.03565877,-0.01900172,0.06979533,0.03905867,0.02430828,-0.0555092,-0.01110252,0.0016512,-0.02478298,0.05436351,0.01767126,-0.02118037,0.0426277,0.0668285,-0.03723982,-0.02833444,0.01277559,-0.05364973,0.0421721,-0.0629841,0.03126369,0.00381307,-0.04644131],"last_embed":{"hash":"1rm3y42","tokens":241}}},"last_read":{"hash":"1rm3y42","at":1768089450812},"class_name":"SmartSource","last_import":{"mtime":1759329344451,"size":872,"at":1768089397381,"hash":"1rm3y42"},"blocks":{"#Week 1: Derivatives and Optimization":[1,24],"#Week 1: Derivatives and Optimization#{1}":[2,6],"#Week 1: Derivatives and Optimization#[[Calculus_Derivative]]":[7,7],"#Week 1: Derivatives and Optimization#[[Calculus_Optimization]]":[8,10],"#Week 1: Derivatives and Optimization#[[Calculus_Optimization]]#{1}":[9,10],"#Week 1: Derivatives and Optimization#Week 2: Gradient and Gradient Descent":[11,13],"#Week 1: Derivatives and Optimization#Week 2: Gradient and Gradient Descent#{1}":[12,13],"#Week 1: Derivatives and Optimization#[[Gradient and Gradient Descent]]":[14,16],"#Week 1: Derivatives and Optimization#[[Gradient and Gradient Descent]]#{1}":[15,16],"#Week 1: Derivatives and Optimization#[[Week 3 - Optimization in Neural Network and Newton's Method]]":[17,24],"#Week 1: Derivatives and Optimization#[[Week 3 - Optimization in Neural Network and Newton's Method]]#[[Lesson 1 - Optimization in Neural Network]]":[19,19],"#Week 1: Derivatives and Optimization#[[Week 3 - Optimization in Neural Network and Newton's Method]]#[[Lesson 2 - Newton's Method]]":[20,24],"#Week 1: Derivatives and Optimization#[[Week 3 - Optimization in Neural Network and Newton's Method]]#[[Lesson 2 - Newton's Method]]#{1}":[21,24]},"outlinks":[{"title":"Calculus_Derivative","target":"Calculus_Derivative","line":7},{"title":"Calculus_Optimization","target":"Calculus_Optimization","line":8},{"title":"Derivative and Optimization Test","target":"Derivative and Optimization Test","line":9},{"title":"Gradient and Gradient Descent","target":"Gradient and Gradient Descent","line":14},{"title":"Linear Regression Using Gradient Descent Exercise","target":"Linear Regression Using Gradient Descent Exercise","line":15},{"title":"Week 3 - Optimization in Neural Network and Newton's Method","target":"Week 3 - Optimization in Neural Network and Newton's Method","line":17},{"title":"Lesson 1 - Optimization in Neural Network","target":"Lesson 1 - Optimization in Neural Network","line":19},{"title":"Lesson 2 - Newton's Method","target":"Lesson 2 - Newton's Method","line":20},{"title":"Optimization in Neural Networks and Newton's Method","target":"Optimization in Neural Networks and Newton's Method","line":21},{"title":"Optimization in Neural Network and Newton's Method Final Test","target":"Optimization in Neural Network and Newton's Method Final Test","line":22}],"task_lines":[],"tasks":{},"codeblock_ranges":[[3,6]],"last_embed":{"hash":"1rm3y42","at":1768089450775}},"smart_blocks:1 PROJECTS/Coursera Mathematic for Machine Learning/Calculus for Machine Learning.md#Week 1: Derivatives and Optimization": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.05147148,-0.018604,0.02401318,-0.02364257,0.00612281,-0.00553729,-0.03417049,0.09922633,0.05733367,-0.01076127,0.04252226,-0.04346497,0.03713673,0.03640676,0.03638649,-0.01546119,0.01414044,0.0773975,-0.06788313,-0.0459695,0.10625257,-0.02482088,-0.06662182,-0.11622339,0.0538035,-0.0686916,-0.02196994,0.02512668,-0.00745579,-0.2099977,0.02611686,-0.03816798,0.03964244,-0.07102656,0.00220197,0.03642495,-0.01241553,0.00967125,-0.08397342,0.02759393,-0.01488295,0.03859832,-0.04129486,-0.03171533,0.00274314,-0.05822134,0.00411815,-0.04091702,-0.02700566,0.01409376,-0.0064098,0.0110106,0.03439965,-0.01604705,0.00475408,0.01034273,0.07477812,0.06179154,0.0083333,0.05413052,0.0119901,0.04869455,-0.20385325,0.07287071,-0.02307048,0.04721209,0.01561775,-0.04549506,0.02679791,0.14677478,-0.01185457,0.0443871,0.01061792,0.03031809,0.01425795,0.02661514,0.03740976,-0.03236751,-0.02135722,0.00167538,0.00507719,0.00347457,-0.05947747,-0.05435998,0.06626962,-0.03840852,-0.00690395,0.00251928,0.02897673,-0.01153123,0.04450563,-0.02539023,-0.02573792,-0.02318742,-0.01166038,0.05391498,0.05234421,-0.00661965,-0.07370701,0.10541163,-0.04312867,0.01609382,-0.01264882,-0.01907594,0.00163845,0.01117993,-0.01760575,-0.0320267,0.02001021,-0.07532695,-0.03845972,-0.00787624,0.00472508,-0.01076504,-0.05840645,0.01919785,-0.00240343,0.0256934,-0.00782305,-0.00052088,-0.03504617,0.01294305,0.08082867,0.01353953,0.03356915,-0.03816222,-0.03739397,0.06722017,-0.00762073,0.02846859,0.06137995,0.00881357,0.00021791,-0.01563777,0.05869667,0.01459949,0.00120301,-0.01379181,-0.00097157,0.02588736,-0.0398344,0.02454148,0.02536046,-0.08617015,-0.08222576,0.13348252,-0.0349661,-0.02633417,-0.02542938,-0.06863388,0.05185063,0.02437853,-0.04555196,-0.00712558,0.0345189,0.05332417,0.08252101,-0.01793126,-0.14176844,-0.00903845,-0.06331,0.01542941,-0.00139626,0.15745915,-0.00064465,0.00099711,0.03956736,-0.00539196,-0.00371137,-0.01618724,0.11263758,0.03485053,-0.04205464,-0.00382872,0.03977487,0.00097019,-0.05365269,0.02079169,-0.06108624,0.04982363,0.00687346,-0.05365566,-0.02374952,-0.01327961,0.04604649,0.00955184,0.01228803,-0.04631495,-0.00854494,0.0249982,-0.04614788,0.00682888,-0.00868658,-0.04208138,-0.0512186,-0.06818116,0.01700479,-0.01197357,-0.03185922,0.00752369,-0.00124729,-0.00919507,0.02554568,0.0234352,-0.03825289,-0.00349808,0.05193389,-0.06223517,0.05451357,0.02351684,-0.03671756,-0.04778966,0.07667361,-0.06488394,-0.022463,0.02290782,0.04094846,-0.00793696,-0.06342218,0.05682417,0.01681072,0.06264943,-0.06043559,-0.16632107,-0.0880719,0.02341984,-0.00208731,0.04555789,-0.06926156,0.07148947,-0.01172052,0.01568371,0.08455589,0.07332793,0.01126615,-0.04231779,-0.0265873,-0.01350076,-0.0430721,0.00066346,0.00762147,-0.02532092,-0.01713606,0.01323062,-0.00559452,0.05930632,-0.11544263,-0.01981506,-0.02016164,0.14163257,-0.02067797,0.09338154,-0.01669875,-0.01540715,-0.04754019,0.01154086,-0.01904676,0.00192734,-0.04050229,0.01749985,-0.06014027,-0.00255413,-0.02701479,-0.00477613,0.04470043,0.01230874,-0.06099742,-0.11634853,-0.03631432,-0.01869718,0.02095991,-0.04327016,0.09494203,0.01002096,0.00592711,0.03505249,-0.05104444,0.04283043,-0.04647036,-0.05186375,-0.01756401,-0.03885263,0.01861511,0.03383039,-0.07446825,0.020713,-0.03865053,0.05643624,-0.04385245,0.03882111,-0.03147562,-0.00137487,0.01797018,0.01104367,0.09689883,0.04700783,0.02738121,0.04907902,-0.01146284,0.05330259,0.00716589,-0.04554543,-0.02396079,0.04146325,-0.03469887,0.06756858,-0.02318052,0.02163963,-0.00553418,0.09430198,-0.0785248,0.01994367,0.03659993,-0.07727657,-0.03803841,-0.01347508,0.00899597,0.07909863,-0.00851107,-0.21569599,0.00925509,0.03671907,-0.03726479,0.03805601,-0.00937614,0.10776094,-0.06054777,-0.09058182,0.00398082,-0.03646166,0.05110104,0.0279466,-0.01937046,0.04207192,-0.00105314,0.04647172,0.00414235,0.04767563,-0.0308924,0.02489743,0.07371712,0.16591914,-0.10137506,0.02989236,0.0270133,-0.03136423,-0.01164747,0.06937563,-0.04532526,0.02079944,0.03782103,0.05136823,-0.07711235,-0.0040223,0.13783291,-0.03682961,0.01992837,0.09309764,0.04213737,0.05991141,0.00672824,-0.0360734,-0.01688816,0.06918111,0.03816181,0.0234536,-0.05518921,-0.00931553,0.00330931,-0.02682706,0.05643345,0.01828621,-0.02212281,0.04458225,0.06536337,-0.03607738,-0.02767032,0.01403512,-0.05153995,0.04122172,-0.06436693,0.03161659,0.00452386,-0.04529213],"last_embed":{"hash":"1rm3y42","tokens":240}}},"text":null,"length":0,"last_read":{"hash":"1rm3y42","at":1768089450788},"key":"1 PROJECTS/Coursera Mathematic for Machine Learning/Calculus for Machine Learning.md#Week 1: Derivatives and Optimization","lines":[1,24],"size":872,"outlinks":[{"title":"Calculus_Derivative","target":"Calculus_Derivative","line":7},{"title":"Calculus_Optimization","target":"Calculus_Optimization","line":8},{"title":"Derivative and Optimization Test","target":"Derivative and Optimization Test","line":9},{"title":"Gradient and Gradient Descent","target":"Gradient and Gradient Descent","line":14},{"title":"Linear Regression Using Gradient Descent Exercise","target":"Linear Regression Using Gradient Descent Exercise","line":15},{"title":"Week 3 - Optimization in Neural Network and Newton's Method","target":"Week 3 - Optimization in Neural Network and Newton's Method","line":17},{"title":"Lesson 1 - Optimization in Neural Network","target":"Lesson 1 - Optimization in Neural Network","line":19},{"title":"Lesson 2 - Newton's Method","target":"Lesson 2 - Newton's Method","line":20},{"title":"Optimization in Neural Networks and Newton's Method","target":"Optimization in Neural Networks and Newton's Method","line":21},{"title":"Optimization in Neural Network and Newton's Method Final Test","target":"Optimization in Neural Network and Newton's Method Final Test","line":22}],"class_name":"SmartBlock","last_embed":{"hash":"1rm3y42","at":1768089450788}},
"smart_blocks:1 PROJECTS/Coursera Mathematic for Machine Learning/Calculus for Machine Learning.md#Week 1: Derivatives and Optimization#{1}": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.05561256,-0.02379609,0.04379581,-0.04623171,0.00612664,-0.0145307,-0.03564966,0.11103002,0.0439849,-0.01675342,0.04582931,-0.05130084,0.02648306,0.03936711,0.04421523,-0.00795802,0.01236655,0.08041371,-0.06877038,-0.0585102,0.1050861,-0.02743667,-0.07557142,-0.09826352,0.06215069,-0.0567051,-0.0064231,0.01022384,0.0055917,-0.20201747,0.00903452,-0.01853061,0.06083957,-0.06608844,-0.01130555,0.04296668,-0.01506377,0.02600856,-0.09663339,0.03467043,-0.00636139,0.04462263,-0.03576079,-0.0334849,-0.01315263,-0.06604675,-0.00558521,-0.0193177,-0.02494532,0.02195188,-0.00282732,0.02026373,0.00886849,-0.0115186,0.00277933,-0.00002879,0.08260895,0.04853796,-0.00050608,0.04354403,0.01261211,0.04573759,-0.18150821,0.07535196,-0.02938913,0.05876869,0.01298427,-0.0530037,0.00219569,0.15339854,-0.00708749,0.03232326,-0.00995572,0.03828406,0.00871352,0.01869489,0.03210968,-0.02982333,-0.02092088,0.02938553,-0.01433113,0.00479057,-0.06270622,-0.04597967,0.03781066,-0.07101601,-0.01339353,-0.0146925,0.04147921,-0.02103591,0.03025585,-0.02890916,-0.01691881,-0.00321676,-0.00223983,0.03468321,0.05166037,-0.01276612,-0.06019364,0.11486548,-0.05250548,0.01288704,0.00194267,-0.02223083,0.01548913,0.01286886,-0.01502092,-0.04240846,0.02106007,-0.096181,-0.02350437,0.00581046,0.01905296,-0.03068523,-0.04664247,0.00156156,0.00530766,0.02699298,0.02136461,0.00643636,-0.03353669,0.02198284,0.08322275,0.00513768,0.0271334,-0.02512081,-0.02231408,0.07530005,-0.02801726,0.03190729,0.05148705,-0.00524252,0.01083935,-0.0183096,0.05627104,0.01223302,0.0131731,-0.00868991,0.00341873,0.05624097,-0.03434914,0.04096832,0.02130328,-0.10485487,-0.06436772,0.14074038,-0.02350449,-0.01716255,-0.02420686,-0.05630697,0.05811719,0.03650245,-0.03603209,-0.0039151,0.02582608,0.03936904,0.07464503,-0.01448175,-0.12859452,-0.01340744,-0.05482209,0.01357192,0.00200688,0.14908929,-0.02555794,-0.01399982,0.04393075,0.0116492,-0.00424207,-0.02891305,0.09235813,0.05608273,-0.03941405,0.01814382,0.05455413,0.0052148,-0.0535771,0.01237258,-0.0614006,0.05320692,0.00889929,-0.05178694,-0.01508131,-0.01843011,0.0404429,0.01126682,0.00572309,-0.04060937,0.00634139,0.02497341,-0.01472929,0.02151009,-0.0073005,-0.0408285,-0.05288096,-0.0630499,0.01877109,-0.00878299,-0.02532233,-0.00433139,-0.01415847,0.00169456,0.01141033,0.03147327,-0.0309784,-0.01627774,0.0544909,-0.0509436,0.05564414,0.00166624,-0.04612089,-0.04445963,0.06801066,-0.05198969,-0.02437854,0.01222168,0.04980535,-0.0167629,-0.06222532,0.03255638,0.01626013,0.08282016,-0.05424837,-0.19602326,-0.06434562,0.0061604,0.02286116,0.04696237,-0.05894655,0.06950012,-0.0217525,-0.00041855,0.09185893,0.06959505,-0.00288633,-0.06674948,-0.0387328,-0.03108013,-0.04527791,-0.00885971,0.00722631,-0.03827124,-0.02519387,0.02935631,0.00154969,0.04647177,-0.13117355,-0.04471842,-0.02140231,0.15114261,-0.00414392,0.068023,-0.01880579,-0.01846828,-0.05766526,-0.01797483,-0.03217893,-0.01199202,-0.0368996,-0.02032737,-0.07928782,-0.00588478,-0.0222616,0.00782796,0.03550561,-0.00471108,-0.05992279,-0.10916087,-0.03364399,-0.02009468,0.01426841,-0.03267977,0.12050768,-0.0089233,0.00448123,0.04789231,-0.01387696,0.01430845,-0.05265366,-0.04983224,-0.0138607,-0.03750172,0.01864073,0.04170699,-0.05630686,0.03001305,-0.03408238,0.05221947,-0.04551938,0.02942659,-0.04927127,0.00939478,-0.00040499,0.01717771,0.10839736,0.02616743,-0.00483993,0.05011529,-0.01729653,0.05214221,0.01462863,-0.03924445,-0.04137881,0.05669173,-0.02872091,0.0601159,-0.01733171,0.02713324,0.00411336,0.08815627,-0.05515463,-0.00521906,0.04248472,-0.0596622,-0.02139487,0.00230227,0.02322635,0.07858498,-0.01064339,-0.23430441,0.01536713,0.03442078,-0.05266569,0.02533861,-0.00986191,0.10155381,-0.05179562,-0.07977131,-0.00167439,-0.00254682,0.05210491,0.00636841,-0.00388228,0.04070774,-0.01150123,0.05606484,-0.01928025,0.05431866,-0.01562429,0.02938597,0.06334027,0.18418053,-0.09964141,0.02679661,0.03689587,-0.0266418,0.00512862,0.06402753,-0.04934704,0.01395983,0.03522497,0.04863965,-0.05996588,0.00135071,0.13395546,-0.03483544,0.0316496,0.08283453,0.04840504,0.05342799,0.02008039,-0.0453321,-0.00700333,0.07351082,0.03309419,0.02704953,-0.05505404,-0.0087657,0.00757121,-0.02109003,0.04365354,-0.00140199,-0.03477983,0.03073446,0.06904354,-0.04845801,-0.01662179,0.0395419,-0.05849389,0.04086538,-0.03686402,0.03887733,-0.00216404,-0.04207492],"last_embed":{"hash":"188kxex","tokens":88}}},"text":null,"length":0,"last_read":{"hash":"188kxex","at":1768089450801},"key":"1 PROJECTS/Coursera Mathematic for Machine Learning/Calculus for Machine Learning.md#Week 1: Derivatives and Optimization#{1}","lines":[2,6],"size":230,"outlinks":[],"class_name":"SmartBlock","last_embed":{"hash":"188kxex","at":1768089450801}},
"smart_blocks:1 PROJECTS/Coursera Mathematic for Machine Learning/Calculus for Machine Learning.md#Week 1: Derivatives and Optimization#[[Week 3 - Optimization in Neural Network and Newton's Method]]": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.06214255,-0.02705666,0.00522287,0.00686333,0.00054639,-0.00630662,-0.05064417,0.04852115,0.01991384,0.00018883,0.01754445,-0.04446308,0.03372467,0.02188153,0.05714019,-0.04107431,-0.01261237,0.05327143,-0.06154084,-0.03259969,0.13103683,-0.02274153,-0.03986096,-0.09463268,0.05103249,-0.05021598,-0.01613654,-0.00463249,-0.01450526,-0.18923467,0.02377441,-0.01240472,0.03570018,-0.05512803,0.00602419,0.02314612,-0.01468881,0.05891375,-0.07598825,0.03286891,0.00423325,0.03815442,-0.03458146,-0.04663198,-0.00144618,-0.06177347,0.02390102,-0.03080037,-0.03623261,-0.03560666,0.00192998,-0.04451601,0.02984185,-0.01035324,0.01386135,-0.00014934,0.04737683,0.06825388,0.01036606,0.05827108,0.00045542,0.04058765,-0.2204212,0.07682335,-0.01955286,0.06635009,-0.00150074,-0.01586545,0.06265925,0.18497445,-0.0206685,0.04576553,0.03108989,0.05675049,0.01977332,0.05043715,0.03035827,-0.04293893,-0.03527966,-0.01029074,0.01772211,-0.01867323,-0.03914516,-0.04228542,0.01447049,-0.02095027,-0.0228364,0.02021507,0.00368623,-0.01515914,-0.00647304,-0.02590142,-0.03601194,0.00492062,-0.01014932,-0.01392696,0.03363145,-0.00154413,-0.04663667,0.09838278,-0.05527996,0.00579884,0.00830008,-0.04436213,0.01682105,0.00364991,0.00871908,-0.09083407,0.00905722,-0.0327663,-0.00280469,0.00565527,-0.02690339,-0.03667223,-0.06401151,0.01498439,0.00417738,0.04878397,0.00439668,-0.02747187,-0.02877901,0.03600007,0.05467002,0.00583508,0.02280121,-0.04453497,-0.04872912,0.06122245,0.02025847,0.04330366,0.04883703,-0.00096651,-0.04544843,-0.01286429,0.0560438,0.04078687,0.01664269,-0.01251962,-0.02423307,0.01698234,-0.05819096,-0.00557246,0.04482844,-0.09593232,-0.08014481,0.12426367,-0.0117021,-0.00161261,-0.00510786,-0.05540588,0.00856925,0.02553951,-0.04982879,-0.05486917,0.03904723,0.05083036,0.09944844,-0.00305256,-0.13342655,0.02027645,-0.05494202,-0.01528582,-0.03889094,0.18965343,0.04580178,-0.01120946,0.0645993,-0.00816354,0.00905112,-0.02589043,0.09168453,0.02840845,-0.05141099,0.00613173,0.04284586,-0.0036802,-0.04168313,-0.00700441,-0.03189205,0.02854435,-0.01109376,-0.04559841,-0.0061191,-0.0110105,0.03886447,0.00442501,0.0037031,-0.02510224,-0.01224168,0.03826528,-0.05411847,-0.00696682,-0.03005107,-0.03030544,-0.028371,-0.0635478,0.01469493,-0.01064567,-0.042758,0.0127637,-0.02974578,-0.01895953,0.02521824,0.04724221,-0.04795817,0.00573315,0.06072862,-0.05806074,0.05052726,0.04894175,-0.04338891,-0.05038312,0.08538131,-0.06157093,-0.01428275,0.03546283,0.01506367,0.00150269,-0.07028218,0.07426447,-0.01534185,0.03953422,-0.04891212,-0.16253002,-0.09020166,0.05805973,-0.03531057,0.08343601,-0.08382945,0.06888648,-0.00971321,0.03563781,0.09857254,0.07813406,0.02710418,-0.01678591,-0.05241548,0.00142463,-0.04449098,-0.02162787,0.00831955,-0.02725866,-0.0150078,-0.00312278,0.02896135,0.06746984,-0.10687663,-0.02179114,-0.01273717,0.12686445,-0.01090289,0.11059805,0.00775326,-0.01008034,-0.00921588,0.01590359,-0.05061125,0.01335922,-0.01890215,0.04342635,-0.04258657,-0.01983445,-0.07022909,-0.00264207,0.05083881,0.01259847,-0.05386069,-0.09351043,-0.04031981,-0.01041494,0.00305912,-0.04252692,0.05585333,-0.00341968,-0.01276154,0.00758073,-0.04202164,0.03791098,-0.02638478,-0.06567825,-0.02770159,-0.01841279,0.0193238,0.02866113,-0.06516357,0.01026175,-0.01325959,0.04054525,-0.02064195,0.04326157,-0.02772813,-0.03038173,0.01855327,0.01997204,0.10440346,0.07343432,0.00975217,0.06184619,-0.02111646,0.05242266,0.00316041,-0.02966431,0.01781468,0.03045581,-0.03940204,0.06026728,-0.01650342,0.04270158,-0.01272706,0.0402669,-0.07342294,0.05246196,0.01642801,-0.05769555,-0.01765918,-0.02523765,0.01408654,0.08546789,0.0223666,-0.24625653,0.05440182,0.07230026,0.01165296,0.05324334,-0.00119687,0.07009768,-0.08595644,-0.05398809,-0.01007429,-0.02236421,0.0354894,0.04030912,-0.01126161,0.04006131,-0.02612512,0.06229318,-0.00530434,0.05875725,-0.04071949,0.0203656,0.05643412,0.1702449,-0.05578114,0.05603914,-0.00791438,0.00110626,-0.01997963,0.04870915,-0.0037523,0.0126554,-0.00367073,0.05656802,-0.07354906,0.03229817,0.1214571,-0.02980378,0.04857434,0.04712712,0.04622525,0.02935375,0.00059829,-0.07360408,-0.02917285,0.05836256,0.04805021,0.02093089,-0.0778521,0.01027385,0.0187693,-0.01957155,0.03742846,0.00234048,-0.0195578,0.03026287,0.06758367,-0.02746561,-0.03841795,-0.04882593,-0.03175645,0.02986901,-0.10689208,0.05679855,0.01209773,-0.01692564],"last_embed":{"hash":"svqtdb","tokens":101}}},"text":null,"length":0,"last_read":{"hash":"svqtdb","at":1768089450812},"key":"1 PROJECTS/Coursera Mathematic for Machine Learning/Calculus for Machine Learning.md#Week 1: Derivatives and Optimization#[[Week 3 - Optimization in Neural Network and Newton's Method]]","lines":[17,24],"size":280,"outlinks":[{"title":"Week 3 - Optimization in Neural Network and Newton's Method","target":"Week 3 - Optimization in Neural Network and Newton's Method","line":1},{"title":"Lesson 1 - Optimization in Neural Network","target":"Lesson 1 - Optimization in Neural Network","line":3},{"title":"Lesson 2 - Newton's Method","target":"Lesson 2 - Newton's Method","line":4},{"title":"Optimization in Neural Networks and Newton's Method","target":"Optimization in Neural Networks and Newton's Method","line":5},{"title":"Optimization in Neural Network and Newton's Method Final Test","target":"Optimization in Neural Network and Newton's Method Final Test","line":6}],"class_name":"SmartBlock","last_embed":{"hash":"svqtdb","at":1768089450812}},
