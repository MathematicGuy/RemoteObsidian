
"smart_sources:MIT Deep Learning Course.md": {"path":"MIT Deep Learning Course.md","last_embed":{"hash":null},"embeddings":{},"last_read":{"hash":"1ermemu","at":1768089396915},"class_name":"SmartSource","last_import":{"mtime":1766324663198,"size":5941,"at":1768089396916,"hash":"1ermemu"},"blocks":{"###[MIT Introduction to Deep Learning](https://www.youtube.com/watch?v=alfdI7S6wCY&t=19s)":[1,8],"###[MIT Introduction to Deep Learning](https://www.youtube.com/watch?v=alfdI7S6wCY&t=19s)#{1}":[3,8],"###[Recurrent Neural Networks, Transformers, and Attention](https://www.youtube.com/watch?v=GvezxUdLrEk)":[9,73],"###[Recurrent Neural Networks, Transformers, and Attention](https://www.youtube.com/watch?v=GvezxUdLrEk)#{1}":[11,27],"###[Recurrent Neural Networks, Transformers, and Attention](https://www.youtube.com/watch?v=GvezxUdLrEk)#Intuition behind Self-Attention":[28,73],"###[Recurrent Neural Networks, Transformers, and Attention](https://www.youtube.com/watch?v=GvezxUdLrEk)#Intuition behind Self-Attention#{1}":[29,73],"###Visualizing Transformer and Attention":[74,78]},"outlinks":[{"title":"MIT Introduction to Deep Learning","target":"https://www.youtube.com/watch?v=alfdI7S6wCY&t=19s","line":1},{"title":"Pasted image 20250309104043.png","target":"Pasted image 20250309104043.png","line":5,"embedded":true},{"title":"Recurrent Neural Networks, Transformers, and Attention","target":"https://www.youtube.com/watch?v=GvezxUdLrEk","line":9},{"title":"Pasted image 20250314071052.png","target":"Pasted image 20250314071052.png","line":11,"embedded":true},{"title":"Pasted image 20250314071311.png","target":"Pasted image 20250314071311.png","line":24,"embedded":true},{"title":"Pasted image 20250314074421.png","target":"Pasted image 20250314074421.png","line":33,"embedded":true},{"title":"Pasted image 20250314075245.png","target":"Pasted image 20250314075245.png","line":36,"embedded":true},{"title":"Pasted image 20250314075755.png","target":"Pasted image 20250314075755.png","line":42,"embedded":true},{"title":"Pasted image 20250314080048.png","target":"Pasted image 20250314080048.png","line":47,"embedded":true},{"title":"Pasted image 20250314080220.png","target":"Pasted image 20250314080220.png","line":49,"embedded":true},{"title":"Pasted image 20250314080347.png","target":"Pasted image 20250314080347.png","line":52,"embedded":true},{"title":"Pasted image 20250314090053.png","target":"Pasted image 20250314090053.png","line":57,"embedded":true},{"title":"Pasted image 20250314091141.png","target":"Pasted image 20250314091141.png","line":67,"embedded":true},{"title":"Pasted image 20250314091330.png","target":"Pasted image 20250314091330.png","line":70,"embedded":true},{"title":"Pasted image 20250314091338.png","target":"Pasted image 20250314091338.png","line":72,"embedded":true}],"task_lines":[],"tasks":{},"codeblock_ranges":[]},
"smart_sources:MIT Deep Learning Course.md": {"path":"MIT Deep Learning Course.md","embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.05911352,-0.02067507,-0.04111748,-0.04040277,-0.02585603,0.01499249,0.00859093,0.04289227,0.06257611,-0.06855021,0.00694529,-0.01277384,0.03759148,0.07819588,0.03981981,0.01061297,-0.00225386,0.03427448,-0.09993849,-0.03711392,0.0946039,-0.03781026,-0.02342989,-0.03127449,0.01016067,-0.00337024,0.03963867,-0.03436827,-0.03572593,-0.29497564,0.06316996,0.03094554,0.09029496,0.01039378,-0.04672265,-0.0433001,-0.0082204,0.02343521,-0.03689136,0.03422281,0.05224329,0.02976266,-0.01363215,-0.02218149,-0.00156577,-0.0688072,-0.01271826,-0.07178705,-0.02657368,-0.02052409,-0.03720557,-0.0386018,-0.00480834,0.00986035,0.03444302,0.03316149,0.04493679,0.05544205,0.09283203,0.02704879,0.04785281,0.0640338,-0.1392982,0.03776328,0.013886,0.00176329,-0.00497862,-0.06382843,-0.00766725,0.07009562,-0.03449272,0.02354435,0.00214956,0.01977268,0.02004543,0.04032141,0.01320292,0.00857155,0.02479518,-0.04516432,0.04946028,-0.02085639,-0.02624657,-0.06134897,0.01104047,0.01449865,-0.01515028,-0.05250619,-0.0424196,-0.0558136,-0.02547983,-0.03708398,-0.01266634,-0.02709986,0.01387313,0.0292021,0.02788994,0.03593898,-0.06809394,0.05934494,-0.03929542,0.06105319,-0.00287833,-0.00069641,0.04845901,-0.00798362,-0.00895035,0.0066594,-0.04605972,0.04039565,-0.01664091,-0.03571695,-0.02256009,-0.01802729,0.04046154,0.00260017,0.07784753,0.01719427,0.0160906,-0.02136046,0.05529543,0.00518866,0.04425993,0.0044582,0.01981507,-0.01676942,-0.03247859,0.09215435,0.0240803,0.01214569,0.04239108,0.00329263,-0.07477041,0.0253655,0.01486972,0.03057707,0.02868863,-0.04241975,-0.02287714,0.00799245,-0.05922554,0.03107119,0.05955148,-0.02386022,-0.09095214,0.11426679,-0.00930482,0.01954063,-0.05629239,-0.03068101,0.01278097,0.05543414,-0.01298425,-0.07250509,0.02389642,-0.00733622,0.04114848,-0.00995309,-0.07363833,0.02316929,-0.09524006,0.01542791,-0.03141534,0.13012166,0.0047893,-0.03266513,0.01057951,-0.02404879,0.00295938,-0.05488892,0.04171177,0.01936882,0.00069999,0.0236221,0.0433001,0.01702485,-0.123882,-0.07643035,-0.00429878,0.03650919,-0.02049838,-0.08993986,-0.01147089,0.00055874,0.03144131,-0.04834308,0.01398261,-0.03835705,0.01730167,-0.01654175,-0.07937418,0.05349914,-0.01159187,0.022241,-0.06046645,-0.0583036,0.02089011,-0.0320321,0.0059087,0.03030948,-0.02180861,-0.02541003,0.03531497,-0.02938436,0.01522666,-0.01324851,-0.00822613,0.01123972,0.07902814,0.0186251,-0.02486307,-0.00214999,-0.00879147,-0.03920798,-0.04464725,-0.03642644,0.05012811,0.04495439,0.00876919,0.03146368,0.02517929,-0.02313511,-0.10953905,-0.1901532,0.00275741,0.06138244,-0.04319591,0.05958828,-0.05504561,0.05349764,0.00346185,0.01670268,0.07463579,0.04580553,0.00046114,-0.06747755,-0.02538402,-0.00778212,0.00255482,0.00701541,0.01455479,-0.0501979,0.02280024,-0.0096014,0.05014842,0.05466588,-0.11292725,-0.01022214,-0.04357126,0.15363654,-0.02752833,0.064316,0.00048463,0.01149752,-0.01581032,-0.0210443,-0.06494608,0.0014077,-0.04275146,0.07319765,-0.01035065,-0.01775194,-0.02203615,-0.08069797,-0.02077959,0.00083648,-0.09664696,-0.06177439,0.04782742,-0.04104847,0.00980829,-0.03889498,-0.0059343,0.08076858,-0.06698883,0.01860801,0.01485902,-0.0253272,-0.03491846,-0.06344746,-0.01371115,-0.06515626,0.02837317,-0.02230256,-0.02224779,-0.0232663,-0.05730129,0.0786263,0.00478131,-0.02311301,0.0124923,0.00360291,-0.01391913,-0.03850526,0.14044172,0.04212001,0.07534707,0.05917617,-0.00801386,0.03284187,-0.02285915,-0.03464869,0.02308543,0.07471655,-0.01736891,0.04929604,0.00783362,0.07982863,0.03142273,0.07806547,-0.06078954,0.00364644,0.06181069,-0.03254345,0.01285551,-0.0526318,-0.02933314,0.00992939,0.00954814,-0.24755479,0.0238401,-0.01283819,0.07925795,0.03241025,-0.01232154,0.08835481,-0.02527967,0.00806206,0.02723059,-0.03748827,0.07016766,0.04157019,-0.0447068,-0.03912799,0.04873129,0.05232851,-0.00789346,0.04640048,-0.0243176,0.03435925,0.06627928,0.20598716,-0.06850466,0.06070835,-0.01729322,-0.02443388,-0.03019224,0.05341868,-0.01514141,-0.00144213,0.00255638,0.08677293,-0.06119168,0.00317575,0.11672945,0.05152931,0.05415209,0.02660561,0.01433221,0.0369427,-0.02251606,0.03606261,0.01093964,0.08267293,-0.00878991,0.05716872,-0.07849205,-0.03860774,0.0614474,0.01343065,-0.02282461,0.04406893,0.02787439,0.03235015,0.05061327,-0.02171674,-0.02138719,-0.04181101,0.01530743,0.02252217,-0.06507777,0.0126893,0.02862712,-0.07440197],"last_embed":{"hash":"1ermemu","tokens":503}}},"last_read":{"hash":"1ermemu","at":1768089432104},"class_name":"SmartSource","last_import":{"mtime":1766324663198,"size":5941,"at":1768089396916,"hash":"1ermemu"},"blocks":{"###[MIT Introduction to Deep Learning](https://www.youtube.com/watch?v=alfdI7S6wCY&t=19s)":[1,8],"###[MIT Introduction to Deep Learning](https://www.youtube.com/watch?v=alfdI7S6wCY&t=19s)#{1}":[3,8],"###[Recurrent Neural Networks, Transformers, and Attention](https://www.youtube.com/watch?v=GvezxUdLrEk)":[9,73],"###[Recurrent Neural Networks, Transformers, and Attention](https://www.youtube.com/watch?v=GvezxUdLrEk)#{1}":[11,27],"###[Recurrent Neural Networks, Transformers, and Attention](https://www.youtube.com/watch?v=GvezxUdLrEk)#Intuition behind Self-Attention":[28,73],"###[Recurrent Neural Networks, Transformers, and Attention](https://www.youtube.com/watch?v=GvezxUdLrEk)#Intuition behind Self-Attention#{1}":[29,73],"###Visualizing Transformer and Attention":[74,78]},"outlinks":[{"title":"MIT Introduction to Deep Learning","target":"https://www.youtube.com/watch?v=alfdI7S6wCY&t=19s","line":1},{"title":"Pasted image 20250309104043.png","target":"Pasted image 20250309104043.png","line":5,"embedded":true},{"title":"Recurrent Neural Networks, Transformers, and Attention","target":"https://www.youtube.com/watch?v=GvezxUdLrEk","line":9},{"title":"Pasted image 20250314071052.png","target":"Pasted image 20250314071052.png","line":11,"embedded":true},{"title":"Pasted image 20250314071311.png","target":"Pasted image 20250314071311.png","line":24,"embedded":true},{"title":"Pasted image 20250314074421.png","target":"Pasted image 20250314074421.png","line":33,"embedded":true},{"title":"Pasted image 20250314075245.png","target":"Pasted image 20250314075245.png","line":36,"embedded":true},{"title":"Pasted image 20250314075755.png","target":"Pasted image 20250314075755.png","line":42,"embedded":true},{"title":"Pasted image 20250314080048.png","target":"Pasted image 20250314080048.png","line":47,"embedded":true},{"title":"Pasted image 20250314080220.png","target":"Pasted image 20250314080220.png","line":49,"embedded":true},{"title":"Pasted image 20250314080347.png","target":"Pasted image 20250314080347.png","line":52,"embedded":true},{"title":"Pasted image 20250314090053.png","target":"Pasted image 20250314090053.png","line":57,"embedded":true},{"title":"Pasted image 20250314091141.png","target":"Pasted image 20250314091141.png","line":67,"embedded":true},{"title":"Pasted image 20250314091330.png","target":"Pasted image 20250314091330.png","line":70,"embedded":true},{"title":"Pasted image 20250314091338.png","target":"Pasted image 20250314091338.png","line":72,"embedded":true}],"task_lines":[],"tasks":{},"codeblock_ranges":[],"last_embed":{"hash":"1ermemu","at":1768089431985}},"smart_blocks:MIT Deep Learning Course.md###[MIT Introduction to Deep Learning](https://www.youtube.com/watch?v=alfdI7S6wCY&t=19s)": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.07017785,-0.02666574,-0.04643733,-0.03147571,-0.02387591,0.00369667,-0.00951457,0.06492057,0.03311415,-0.05584865,0.04531531,-0.03176506,0.0415929,0.05299827,0.02735727,-0.02233016,-0.0027241,0.04359961,-0.12272316,0.01975789,0.14041674,-0.03121329,-0.03602525,-0.0349987,0.02300663,0.0504915,0.02047725,-0.0246193,-0.0172715,-0.28494954,0.01446688,0.04607683,0.09005405,-0.01160783,-0.0160663,-0.02322881,0.00147344,0.02938335,-0.03138852,0.03971055,0.05006821,-0.01094182,0.01687173,-0.01517593,0.00280633,-0.07004358,-0.01754324,-0.02257601,-0.03858253,-0.01306234,-0.01033435,0.00594006,-0.01884415,0.02122103,0.03769792,0.04791779,0.06336042,0.0446399,0.07532572,0.06467006,0.05380311,0.0688771,-0.16386878,0.0473606,0.01417921,-0.01310204,0.02086481,-0.08967818,0.00169903,0.06530596,-0.04784375,0.02924612,0.01126091,0.02266549,0.03865354,0.00968403,0.01837425,-0.00101645,0.00752121,-0.04687529,0.04130581,-0.04271413,-0.02773237,0.00233206,-0.04268807,0.00922664,0.00466397,-0.06746364,-0.03952535,-0.02856179,-0.02906117,-0.02247502,-0.0240274,-0.05131596,-0.0234391,0.02081747,0.0163982,0.02417762,-0.04620696,0.08086891,-0.05464183,0.07075068,-0.01111805,0.02680331,0.04362346,-0.00336911,-0.01007384,-0.00178868,-0.02461861,0.00813958,-0.02904498,-0.03140608,-0.03006771,-0.02617898,0.01746954,-0.04908048,0.05164896,0.002843,0.02937664,-0.03759576,0.0746242,0.00247626,0.05524947,0.02348377,0.00622698,-0.01062071,-0.03440617,0.0799098,0.0091256,0.05209918,0.0327802,-0.00699696,-0.04145677,0.02819991,-0.00093482,0.02497811,0.01329405,0.00666462,-0.04185778,0.05490338,-0.06488548,0.01607461,0.02721643,-0.0057131,-0.07379908,0.0544969,-0.02916414,0.04320385,-0.04068975,0.0023618,0.02363062,0.06943343,-0.01411385,-0.05164068,0.01493287,0.01423011,0.01030061,-0.02216623,-0.06299607,0.03408827,-0.09151193,-0.02284633,-0.06489649,0.16037261,-0.00821356,-0.03469539,0.01670012,-0.00850088,0.03365121,-0.062297,0.02316509,0.01042984,0.01164134,-0.02771571,0.05119637,0.01742607,-0.1167881,-0.11002975,-0.00128595,0.03224291,-0.03938519,-0.07074244,-0.01984664,0.00679058,0.03862616,-0.01147208,-0.01307483,-0.04007951,0.02972648,-0.06054497,-0.07342328,0.07158905,-0.05129628,-0.01265616,-0.03912655,-0.06373977,0.02113397,-0.03455184,-0.00179349,0.05998068,0.00121649,-0.02942047,0.03776221,-0.01017488,0.02131275,-0.0237032,0.02592514,0.01520395,0.06477746,0.02472801,-0.00630956,-0.01705599,-0.01553743,-0.06268305,-0.02696065,-0.03437646,0.07301266,0.02222671,0.01262856,0.00418395,-0.01285535,-0.00676569,-0.11239967,-0.18909346,-0.03414957,0.03355523,-0.06384017,0.08555616,-0.03870794,0.05242577,-0.00397464,-0.008308,0.06817968,0.05886304,0.04835327,-0.04804162,-0.00854091,-0.03037305,-0.00563742,0.01854472,-0.03646303,-0.06328961,0.0385194,-0.03429866,0.05563862,0.01596747,-0.11744819,-0.00359477,-0.03232292,0.13978347,-0.04241026,0.07347777,0.01452291,0.02655366,-0.01942946,-0.03459595,-0.04584679,0.01948696,-0.02185516,0.08427385,-0.0591675,-0.04037556,-0.06023631,-0.04341181,-0.0185766,-0.00254467,-0.0763916,-0.03668581,0.04650817,-0.06313026,0.01645572,-0.06406034,-0.01592642,0.03730326,-0.04354851,0.04857868,0.01732723,-0.00435791,-0.00391644,-0.05592474,0.00646172,-0.03325269,0.04743646,-0.0401274,-0.02016385,-0.04705555,-0.06462224,0.08093808,0.02200334,-0.03518754,-0.01449344,0.04402505,-0.03421454,-0.0019962,0.14237268,0.02723924,0.06133442,0.0589621,-0.01243034,0.01482298,0.014436,-0.02434176,-0.00542859,0.07998388,-0.00509601,0.04072606,0.02606023,0.02092467,0.01675453,0.06752755,-0.07401788,0.02584883,0.02373949,-0.03021808,0.01084581,-0.05879273,-0.00148009,0.03113184,-0.0126558,-0.24307382,-0.00336572,-0.01842695,0.05769771,-0.0069211,0.00334875,0.11271425,-0.01878609,-0.0398406,0.02483581,0.00923434,0.05833253,0.03726343,-0.01639901,-0.0086867,0.03165155,0.05255016,-0.03322849,0.05243387,-0.01294402,0.05921658,0.08265331,0.21643403,-0.07608811,0.07400378,0.02490819,0.0173514,-0.0135409,0.01746357,-0.01595053,0.02280816,0.01164942,0.06013954,-0.07848557,0.00539611,0.12825182,0.06379899,0.06708495,-0.00255175,-0.01158151,-0.02283238,-0.02017959,0.029249,0.03821112,0.06046904,-0.01298344,0.05115699,-0.0574813,0.01015123,0.02097214,0.03155775,0.00884041,0.03032422,0.02229688,0.00837869,0.04217523,-0.02217589,-0.02735357,-0.04852434,0.02524568,0.03846582,-0.03471472,0.03039564,0.02340879,-0.08499064],"last_embed":{"hash":"15lgb51","tokens":130}}},"text":null,"length":0,"last_read":{"hash":"15lgb51","at":1768089432037},"key":"MIT Deep Learning Course.md###[MIT Introduction to Deep Learning](https://www.youtube.com/watch?v=alfdI7S6wCY&t=19s)","lines":[1,8],"size":435,"outlinks":[{"title":"MIT Introduction to Deep Learning","target":"https://www.youtube.com/watch?v=alfdI7S6wCY&t=19s","line":1},{"title":"Pasted image 20250309104043.png","target":"Pasted image 20250309104043.png","line":5,"embedded":true}],"class_name":"SmartBlock","last_embed":{"hash":"15lgb51","at":1768089432037}},
"smart_blocks:MIT Deep Learning Course.md###[MIT Introduction to Deep Learning](https://www.youtube.com/watch?v=alfdI7S6wCY&t=19s)#{1}": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.06842003,-0.02426755,-0.04692014,-0.03377815,-0.02273474,0.00480084,-0.00875023,0.06193002,0.03513309,-0.05422562,0.04690478,-0.03140483,0.04227635,0.05233102,0.02425028,-0.02476425,-0.0013938,0.0416669,-0.12121743,0.01928075,0.1424543,-0.02775749,-0.0354018,-0.03102645,0.02383591,0.05419586,0.01843688,-0.02087429,-0.01758507,-0.27762234,0.01345161,0.04000387,0.0856123,-0.01365155,-0.01854755,-0.02325719,-0.00080865,0.03076174,-0.03159992,0.03859536,0.04795676,-0.01094883,0.02483081,-0.01467782,-0.00099213,-0.07094686,-0.01641293,-0.02416541,-0.03623005,-0.01281429,-0.00763486,0.00483295,-0.0204316,0.01927018,0.03648094,0.05142334,0.06152117,0.0463219,0.07265657,0.06694414,0.05236528,0.06813553,-0.16363852,0.05096514,0.01346084,-0.01330416,0.02115704,-0.09024666,0.00651333,0.06577667,-0.05383982,0.02872161,0.01199751,0.0253446,0.03978926,0.00709568,0.01480141,-0.00355021,0.01099773,-0.04668932,0.03904101,-0.04153918,-0.02710705,0.0043464,-0.04261833,0.0097799,0.00582733,-0.07423387,-0.03810231,-0.02991154,-0.03160442,-0.02376528,-0.02853264,-0.05364927,-0.0256728,0.01798577,0.01628103,0.02241675,-0.04372396,0.08178423,-0.05742026,0.07303105,-0.01044112,0.02636686,0.04625804,-0.00485713,-0.0133405,-0.00235348,-0.02326563,0.00744162,-0.02784075,-0.03160665,-0.03389812,-0.02845162,0.0188927,-0.05172303,0.04964677,-0.00017331,0.03042527,-0.03754978,0.07660146,0.00190365,0.05283596,0.02176556,0.00259454,-0.00580674,-0.03174373,0.08135612,0.00592262,0.05046989,0.03143601,-0.00618366,-0.04544958,0.02568823,-0.00017701,0.02640533,0.01197796,0.00729324,-0.0466135,0.05579645,-0.06243641,0.01798944,0.02499713,-0.00459763,-0.07230647,0.05463196,-0.02666466,0.04911111,-0.0428933,0.00604881,0.02643668,0.07104019,-0.01327806,-0.0485661,0.01247683,0.01489629,0.00329506,-0.02437234,-0.0575506,0.03417639,-0.09480757,-0.0245037,-0.06247059,0.15976013,-0.00929809,-0.03238833,0.01809306,-0.00787682,0.03483261,-0.05962865,0.02409457,0.0091718,0.01246988,-0.03204875,0.05384129,0.01600557,-0.11594168,-0.11043991,-0.00049776,0.03398492,-0.03579683,-0.06805231,-0.02254459,0.0040335,0.0407416,-0.01001809,-0.01466513,-0.03984524,0.03021202,-0.06196705,-0.07143885,0.07501274,-0.05129622,-0.01490691,-0.03785572,-0.06371677,0.01805452,-0.03333507,-0.00074396,0.05844536,0.00737111,-0.03084703,0.03605725,-0.00956687,0.02500893,-0.0237344,0.02619665,0.01698786,0.06453778,0.02189049,-0.00505213,-0.01745509,-0.01599109,-0.06413892,-0.02834989,-0.03325818,0.07208867,0.01968741,0.01027193,0.00062389,-0.01138645,-0.00574868,-0.10893774,-0.18898602,-0.03538712,0.03365025,-0.06270456,0.08640688,-0.03926128,0.05501914,-0.00580704,-0.00703394,0.06581942,0.0579412,0.04982148,-0.0487137,-0.00586356,-0.03528867,-0.00483364,0.0193574,-0.03618025,-0.06312899,0.03856202,-0.03167039,0.05451812,0.01736782,-0.11869742,-0.00536793,-0.03009146,0.14010784,-0.04335964,0.07013678,0.01169305,0.02479225,-0.01832017,-0.0356736,-0.04549338,0.0218086,-0.02109849,0.07859353,-0.0630283,-0.04091388,-0.06104575,-0.03751644,-0.01469909,-0.00445358,-0.07325933,-0.03726871,0.04645734,-0.06592433,0.01806101,-0.06459303,-0.01626153,0.03597347,-0.04626821,0.05080914,0.01625864,-0.00623915,-0.00467796,-0.05518426,0.00611194,-0.03218712,0.04677412,-0.0456271,-0.02178572,-0.04991857,-0.06084657,0.08099567,0.01896858,-0.03758742,-0.01355507,0.04669344,-0.03601582,-0.00506378,0.14354658,0.02288337,0.06336258,0.0580446,-0.01346856,0.01258348,0.00797353,-0.02712075,-0.00591816,0.07718759,0.0005622,0.03826845,0.02928702,0.01862462,0.01447346,0.06787107,-0.07390674,0.02617253,0.02451698,-0.03080687,0.01022712,-0.06128379,0.00123641,0.03319924,-0.01047776,-0.24692257,-0.00232619,-0.02273776,0.05639192,-0.00822056,0.00012728,0.11197077,-0.01845146,-0.03978362,0.02653676,0.01072228,0.06165691,0.03490917,-0.01538498,-0.01097847,0.03291609,0.05317312,-0.03360731,0.05392331,-0.01424319,0.06058952,0.08191328,0.21599276,-0.07166241,0.07369676,0.02171352,0.0184428,-0.01183281,0.01251912,-0.01549394,0.03057062,0.01086145,0.06221076,-0.078451,0.00339185,0.13628319,0.06574389,0.06538777,-0.001068,-0.01005201,-0.02191677,-0.01835911,0.0315624,0.03873793,0.06108657,-0.01365878,0.05108571,-0.05631547,0.01017874,0.01990404,0.03163639,0.01489776,0.03135941,0.02176669,0.01052696,0.04110312,-0.02186881,-0.02264835,-0.04603065,0.02549184,0.04142977,-0.02648624,0.02807859,0.02436139,-0.08700505],"last_embed":{"hash":"40uj81","tokens":128}}},"text":null,"length":0,"last_read":{"hash":"40uj81","at":1768089432057},"key":"MIT Deep Learning Course.md###[MIT Introduction to Deep Learning](https://www.youtube.com/watch?v=alfdI7S6wCY&t=19s)#{1}","lines":[3,8],"size":341,"outlinks":[{"title":"Pasted image 20250309104043.png","target":"Pasted image 20250309104043.png","line":3,"embedded":true}],"class_name":"SmartBlock","last_embed":{"hash":"40uj81","at":1768089432057}},
"smart_blocks:MIT Deep Learning Course.md###[Recurrent Neural Networks, Transformers, and Attention](https://www.youtube.com/watch?v=GvezxUdLrEk)": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.06470948,-0.02496188,-0.01520566,-0.03474818,-0.0220577,0.03642863,-0.02683671,0.00203394,0.05653485,-0.05807344,-0.02070471,-0.02357628,0.0429615,0.07586286,0.04091861,0.03169962,-0.01588228,0.03124938,-0.06063168,-0.07313354,0.07811755,-0.04327323,-0.00874433,-0.02930917,0.00602431,-0.03493456,0.03743388,-0.04864624,-0.03953627,-0.2703833,0.07901385,-0.00306636,0.04762745,0.02900548,-0.0336946,-0.03600864,-0.01219182,0.0510329,-0.02783459,0.03414444,0.00134791,0.05787937,-0.03525824,-0.02580752,0.01800779,-0.03682022,-0.00100314,-0.07362854,-0.02696585,-0.03365197,-0.05358591,-0.04678679,-0.00906758,0.00064053,0.03520385,0.03264725,0.03546974,0.05885124,0.08409949,-0.01895308,0.02994937,0.0395244,-0.13811229,0.02970176,0.03691303,0.02131536,-0.0218727,-0.01312089,-0.01200244,0.07954802,-0.02126458,0.02342132,-0.00788686,0.0428502,0.00087897,0.06096573,-0.00371599,-0.00130041,0.02078173,-0.02247943,0.03254408,-0.00584822,-0.02039632,-0.09135681,0.01594635,-0.0038206,-0.02323395,-0.02496288,-0.01354757,-0.06232317,-0.02063,-0.03450066,-0.00140023,0.02589773,0.00289001,0.01940682,0.02577689,0.0596276,-0.06941814,0.06704714,-0.02597574,0.05772598,0.00932631,-0.01853168,0.04543608,-0.00131716,-0.01671111,0.00509045,-0.06630665,0.04707966,-0.01032071,-0.02239748,0.00239684,-0.03780501,0.04557407,0.02394658,0.08366501,0.04379547,-0.01152773,0.01629025,-0.00203105,0.01273386,0.01153858,-0.00508048,0.02726034,-0.02506488,-0.0103268,0.09138303,0.03755511,0.00296336,0.03964204,0.00893199,-0.0866106,0.01110109,0.02238731,0.03377814,0.03265627,-0.06686863,0.00695727,-0.02844901,-0.05975667,0.01386291,0.0517677,-0.03361396,-0.07847172,0.15501621,0.00128924,-0.00195331,-0.07107811,-0.05280621,-0.01682536,0.03173718,-0.0122096,-0.09592985,0.03396288,-0.01116222,0.06110044,0.01044753,-0.07973341,-0.00309975,-0.05265189,0.01610722,-0.01564994,0.10815118,0.02225432,-0.03292479,-0.01621024,-0.0160861,0.0110089,-0.05360276,0.04899769,0.0139892,0.00057162,0.03853571,0.02607298,0.00780758,-0.13066235,-0.03110028,-0.00903485,0.03029552,-0.00544331,-0.0685833,-0.00324355,0.00459232,0.0236689,-0.08089392,0.0350641,-0.04335056,0.00649905,0.03141195,-0.07033318,0.01080711,-0.00283477,0.05656959,-0.05552093,-0.05645542,0.02509325,-0.00529552,0.01009537,-0.01066929,-0.02895874,-0.00880752,0.0214008,-0.02592222,0.00500426,0.00122265,-0.02670075,0.00868656,0.06680381,0.02625132,-0.03721636,0.00470356,0.0070226,-0.02522757,-0.0386775,-0.00979846,0.02120502,0.06141852,0.02596419,0.05006269,0.05443264,-0.03446214,-0.08270583,-0.1962045,0.02590388,0.06118584,-0.03989539,0.05340841,-0.07754747,0.03390843,-0.00805915,0.03904418,0.06617001,0.03063598,-0.0364201,-0.04524903,-0.03041218,0.00753021,0.01888032,-0.00322813,0.0643135,-0.02787363,0.02729552,0.02213417,0.0466315,0.0591584,-0.10412506,-0.01015362,-0.03092957,0.1729255,-0.01456912,0.06492593,-0.0174789,0.01168325,0.00577848,-0.02642117,-0.08311193,0.00344792,-0.04349906,0.06124466,0.02716527,0.00092501,-0.01068165,-0.08796362,0.0025932,-0.00009675,-0.09128485,-0.07635766,0.03589897,-0.02895255,-0.00227816,-0.01721735,0.0194884,0.07851384,-0.07281171,0.02334596,0.00362077,-0.02167854,-0.04609547,-0.0727062,-0.02497116,-0.06165878,0.02231922,0.01653503,-0.0118997,-0.02528217,-0.04114741,0.0495204,0.01105527,-0.00127277,-0.00345289,-0.01651086,0.00185287,-0.0448729,0.13042067,0.04490652,0.05996273,0.0633158,-0.00955147,0.02246107,-0.04793729,-0.03416148,0.0244079,0.08119392,-0.04289597,0.07680947,0.01243368,0.1269809,0.02838505,0.06673355,-0.01435754,-0.01251143,0.07151721,-0.02878594,0.01319619,-0.06010067,-0.03703639,-0.00398319,0.00734898,-0.25184986,0.0589653,0.01007211,0.0890464,0.0493827,-0.0018704,0.05827225,-0.02995821,0.0106861,0.00306197,-0.07900088,0.0730747,0.03140829,-0.04230575,-0.03532691,0.04119689,0.06849135,-0.0084245,0.03724073,-0.04110157,0.02776318,0.02766176,0.19260141,-0.03859011,0.05684132,-0.03843892,-0.03992884,-0.01411716,0.07837165,0.00206412,-0.03140859,-0.01546629,0.10103346,-0.04738153,-0.00080273,0.09256434,0.03209347,0.03862043,0.05749077,0.02345383,0.07902949,-0.02568928,0.04028957,-0.0161331,0.08968117,-0.00856132,0.03027752,-0.08065631,-0.0731262,0.0797879,-0.02230077,-0.03919456,0.03759217,0.00256205,0.03951125,0.06134581,-0.04026485,-0.03177437,-0.02709795,-0.01750429,0.01663872,-0.08573789,0.00142338,0.01239249,-0.07049429],"last_embed":{"hash":"gwsisk","tokens":465}}},"text":null,"length":0,"last_read":{"hash":"gwsisk","at":1768089432065},"key":"MIT Deep Learning Course.md###[Recurrent Neural Networks, Transformers, and Attention](https://www.youtube.com/watch?v=GvezxUdLrEk)","lines":[9,73],"size":5451,"outlinks":[{"title":"Recurrent Neural Networks, Transformers, and Attention","target":"https://www.youtube.com/watch?v=GvezxUdLrEk","line":1},{"title":"Pasted image 20250314071052.png","target":"Pasted image 20250314071052.png","line":3,"embedded":true},{"title":"Pasted image 20250314071311.png","target":"Pasted image 20250314071311.png","line":16,"embedded":true},{"title":"Pasted image 20250314074421.png","target":"Pasted image 20250314074421.png","line":25,"embedded":true},{"title":"Pasted image 20250314075245.png","target":"Pasted image 20250314075245.png","line":28,"embedded":true},{"title":"Pasted image 20250314075755.png","target":"Pasted image 20250314075755.png","line":34,"embedded":true},{"title":"Pasted image 20250314080048.png","target":"Pasted image 20250314080048.png","line":39,"embedded":true},{"title":"Pasted image 20250314080220.png","target":"Pasted image 20250314080220.png","line":41,"embedded":true},{"title":"Pasted image 20250314080347.png","target":"Pasted image 20250314080347.png","line":44,"embedded":true},{"title":"Pasted image 20250314090053.png","target":"Pasted image 20250314090053.png","line":49,"embedded":true},{"title":"Pasted image 20250314091141.png","target":"Pasted image 20250314091141.png","line":59,"embedded":true},{"title":"Pasted image 20250314091330.png","target":"Pasted image 20250314091330.png","line":62,"embedded":true},{"title":"Pasted image 20250314091338.png","target":"Pasted image 20250314091338.png","line":64,"embedded":true}],"class_name":"SmartBlock","last_embed":{"hash":"gwsisk","at":1768089432065}},
"smart_blocks:MIT Deep Learning Course.md###[Recurrent Neural Networks, Transformers, and Attention](https://www.youtube.com/watch?v=GvezxUdLrEk)#{1}": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.06998909,-0.02781908,0.00312318,-0.03184117,-0.02596635,0.03460951,-0.07453293,-0.00122471,0.04636324,-0.05799325,-0.00897606,-0.03291769,0.04984241,0.07913607,0.01794905,0.02957918,-0.00632351,0.02817536,-0.02381997,-0.06984208,0.06639104,-0.06986755,-0.01045233,-0.03114394,0.00728189,-0.02578032,0.04222758,-0.03944201,-0.03528471,-0.27955851,0.08692817,0.00273462,0.01146095,0.03469629,-0.02641575,-0.04645262,0.00580734,0.03558145,-0.02856934,0.03733524,-0.00280276,0.08486383,-0.03658628,-0.04154046,0.02744227,-0.03671197,-0.00313014,-0.07157321,-0.02132039,-0.0330149,-0.0479176,-0.04741663,-0.00114316,0.00432585,0.03520555,0.05845373,0.02981071,0.05809854,0.09465183,-0.00967818,0.01392848,0.0466998,-0.14301591,0.02327923,0.05692816,0.01597418,-0.01897074,-0.00359641,-0.02283405,0.08534203,-0.0246312,0.02519029,-0.01394462,0.04768322,-0.00704956,0.05850367,-0.00520741,0.00262745,-0.00837839,-0.01135224,0.0383765,-0.00473101,-0.02105432,-0.10647496,-0.00198653,-0.01707621,-0.01765989,-0.03541346,-0.02788251,-0.06038911,-0.01433734,-0.00732787,0.0167142,0.03565211,-0.0071452,0.01736581,0.02382175,0.04752181,-0.07776689,0.06604221,-0.03181165,0.05822258,0.01046695,0.01603108,0.05297657,0.03031193,-0.01204176,0.01317019,-0.0752737,0.0369083,-0.01433211,-0.01557989,0.01986767,-0.04875145,0.05640125,0.00550827,0.0679151,0.03953494,-0.03199207,0.03474269,-0.01592018,0.03174505,0.01621144,0.00609358,0.02642444,-0.02917511,-0.02494533,0.08645707,0.03198364,0.0213634,0.0198431,0.00900877,-0.07114591,-0.00971952,0.0271306,0.03502118,0.03380238,-0.08076955,0.02431743,-0.01441671,-0.06652218,0.00017251,0.05197892,-0.04150141,-0.06845195,0.13620099,0.01979073,0.02099952,-0.07427654,-0.0190492,-0.02692514,0.0156003,-0.01703514,-0.10195215,0.04119768,-0.02784025,0.05122221,0.01623104,-0.08528502,-0.00451633,-0.05354876,-0.01070082,-0.01055326,0.11743609,0.01526069,-0.01810975,-0.00983307,-0.01697689,0.02329308,-0.04865563,0.03947037,0.03747131,0.01402953,0.01466754,0.01893186,-0.00304498,-0.13901113,-0.05066017,0.0007305,0.02587886,0.01743144,-0.05370158,-0.00270806,0.00893041,0.02981643,-0.06618642,0.02263435,-0.04906766,0.00303515,0.02167562,-0.08210661,0.02354757,0.00656158,0.04901455,-0.04632504,-0.04649139,0.01300695,0.01404118,0.03160959,0.00042509,-0.02644974,-0.01909532,0.01874959,-0.02367184,-0.01175778,0.00004683,-0.03331999,0.00472446,0.04591234,0.04352845,-0.02887615,0.00213522,0.01379942,-0.02692011,-0.03815051,0.00772851,0.02190965,0.06603175,0.04595412,0.0400808,0.08051213,-0.01659476,-0.08420493,-0.20721014,0.0338573,0.04786472,-0.06599247,0.07414161,-0.0749203,0.04856784,-0.01760796,0.02649071,0.05201481,0.0341361,-0.02558144,-0.04463645,-0.0443269,0.00225036,0.01554171,-0.01208855,0.06396674,-0.02465333,0.01751451,0.00895568,0.051496,0.03437402,-0.08777358,0.00907546,-0.03593828,0.17457168,-0.01546633,0.05740396,-0.0232726,0.02395171,0.03921697,-0.03442878,-0.08201704,-0.0033816,-0.03351102,0.0775425,-0.00252817,0.009915,-0.01256204,-0.07979718,0.01582708,-0.01492896,-0.0878151,-0.07253788,0.04111371,-0.03477488,-0.00554054,-0.01675214,0.01464818,0.05023066,-0.08451447,0.01594173,0.01118241,0.01127736,-0.03094281,-0.08871664,-0.00448826,-0.06086555,0.0285366,0.01848467,-0.00874338,-0.03836954,-0.03023812,0.04364071,0.02584102,-0.00359466,-0.01602379,-0.01717888,0.00299901,-0.00581099,0.11884695,0.04767815,0.05085355,0.07462033,-0.02317476,0.01477051,-0.04572555,-0.02918475,0.0304397,0.07986782,-0.05282617,0.06692915,0.03486025,0.11422861,0.02094464,0.06087437,-0.00248204,-0.01964233,0.07470117,-0.02632241,0.01661057,-0.06614234,-0.02361901,0.02869366,0.00372349,-0.25355449,0.07498194,0.023467,0.0821077,0.05426635,0.01599952,0.04285525,-0.02406039,-0.00701101,-0.00036953,-0.06741066,0.09351271,0.03485638,-0.01947554,-0.03056664,0.03159953,0.06508238,-0.01598004,0.02771489,-0.05379895,0.03220737,0.03061204,0.1693273,-0.02568556,0.04627647,-0.01796164,-0.04082204,0.00965211,0.06564825,0.00032455,-0.05755692,-0.00625432,0.07722153,-0.0585182,-0.00337685,0.10099056,0.03622742,0.04864128,0.06428488,0.02159603,0.06428888,-0.02325668,0.01589977,-0.01609942,0.07212056,-0.01490343,0.01043624,-0.08203277,-0.06232205,0.0600029,-0.02343498,-0.05096056,0.03362172,0.00606349,0.03819411,0.06231317,-0.04263027,-0.03683877,-0.0456156,-0.0240004,0.02683154,-0.08313957,-0.00286644,0.02528994,-0.08153514],"last_embed":{"hash":"6skora","tokens":243}}},"text":null,"length":0,"last_read":{"hash":"6skora","at":1768089432092},"key":"MIT Deep Learning Course.md###[Recurrent Neural Networks, Transformers, and Attention](https://www.youtube.com/watch?v=GvezxUdLrEk)#{1}","lines":[11,27],"size":763,"outlinks":[{"title":"Pasted image 20250314071052.png","target":"Pasted image 20250314071052.png","line":1,"embedded":true},{"title":"Pasted image 20250314071311.png","target":"Pasted image 20250314071311.png","line":14,"embedded":true}],"class_name":"SmartBlock","last_embed":{"hash":"6skora","at":1768089432092}},
"smart_blocks:MIT Deep Learning Course.md###[Recurrent Neural Networks, Transformers, and Attention](https://www.youtube.com/watch?v=GvezxUdLrEk)#Intuition behind Self-Attention#{1}": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.05991926,-0.00319778,-0.04101411,-0.04877827,-0.00863633,0.05411023,0.04690295,0.00370754,0.0652045,-0.04533968,-0.04529372,-0.02159858,0.03711867,0.07430219,0.05427411,0.01431513,-0.03345848,0.04640292,-0.10502761,-0.05866266,0.0976074,-0.0073834,0.00416802,-0.03503688,0.01138799,-0.05353147,0.0165624,-0.04287294,-0.013009,-0.24043785,0.04397287,-0.00908196,0.07366883,0.02330263,-0.04825677,-0.02358659,-0.0622999,0.04230555,-0.03059129,0.01494319,0.03285191,0.00995353,-0.02244252,-0.03481345,0.00808736,-0.05079157,0.01330577,-0.08839344,-0.02766407,-0.0413716,-0.02501405,-0.02239424,-0.01846941,0.02779496,0.04687178,0.00990387,0.04563216,0.04303537,0.04249626,0.0019452,0.06638795,0.0278779,-0.14647803,0.05005769,-0.01645502,0.03268632,-0.00860201,-0.02398256,0.01009666,0.068999,-0.01042249,0.0067246,-0.00365949,0.02099627,0.01528533,0.06022596,0.04087078,-0.02493202,0.03767437,-0.03221128,0.02989153,0.00565887,-0.00049,-0.03742694,0.04102489,0.03307253,0.01312982,-0.02682817,-0.00079731,-0.03638211,-0.03160986,-0.06998887,-0.04810265,-0.01410263,0.01818562,-0.00401864,0.03222079,0.0319029,-0.07718214,0.08427504,-0.01023007,0.0385561,-0.02427884,-0.03209431,0.02535874,-0.05338564,-0.01602698,-0.01388679,-0.03592477,0.03045195,-0.01860965,-0.01293412,-0.04857333,-0.01724875,-0.0007064,0.04880883,0.07636468,0.0314024,0.03053377,-0.03142562,0.00393239,-0.02574114,0.02072421,-0.01510973,0.05348007,-0.02452272,0.01402749,0.08188196,0.03741767,-0.00596667,0.06935239,-0.0229622,-0.08399155,0.01685036,0.00545311,0.02820018,0.02051255,-0.02801406,-0.02397058,-0.02798676,-0.04402489,0.01798163,0.03855035,-0.02218581,-0.10763387,0.14271189,-0.05168265,-0.04204177,-0.01580727,-0.08439778,-0.03305756,0.02055653,-0.01869712,-0.04906601,0.02464277,0.01710308,0.04628662,-0.00803479,-0.09331848,0.00470699,-0.08217473,0.01515957,-0.04547442,0.11797787,0.04918289,-0.03608523,-0.03572874,-0.02339044,0.01328036,-0.02733648,0.07628023,-0.01121859,-0.02526065,0.07196391,0.05993221,0.01686335,-0.08570928,0.00562473,-0.01852977,0.03592166,-0.03129831,-0.10947736,-0.01346058,-0.00902469,0.00344249,-0.06824991,0.03715167,-0.03584737,0.01522592,0.03583434,-0.03996129,0.01880498,-0.02405819,0.02192339,-0.05552874,-0.02717357,0.01557025,-0.01398957,-0.01031526,-0.00807672,-0.02942249,-0.00856717,-0.00184321,-0.01367741,0.01249132,-0.01523455,0.00486164,0.02021327,0.07637748,-0.00484805,-0.049692,0.01935923,0.03856195,-0.05691798,-0.03079748,-0.04763337,0.0126554,0.04752766,-0.002034,0.02723991,-0.00305341,-0.02771486,-0.05134208,-0.18639565,0.00315826,0.05042047,-0.00882806,0.00949025,-0.06563974,0.05122196,0.017934,0.06235756,0.07860219,0.04420194,-0.02585141,-0.03985948,-0.01155115,0.01437518,0.02653113,0.04747513,0.04629444,-0.02402834,0.02607831,0.02436233,0.02529405,0.04737489,-0.09814022,0.01883179,-0.01516,0.15363932,0.02610971,0.07194047,0.00675032,0.00223805,-0.0393724,-0.01984738,-0.08467746,0.02995558,-0.03750205,0.02989006,0.05302161,-0.00835317,-0.02089098,-0.08462697,-0.01938698,0.00861697,-0.1045293,-0.06226638,0.02560321,-0.02821989,0.00801717,-0.03331551,0.04531841,0.10056933,-0.0411715,0.03202229,0.00184079,-0.05248505,-0.05295888,-0.02538604,-0.03739718,-0.06328364,0.03514308,0.00507709,-0.02322689,-0.01511189,-0.05563955,0.04013715,-0.01116437,0.00869785,0.05054602,0.02305567,0.02416367,-0.0824739,0.11203437,0.06452624,0.06383209,0.05141094,0.0060259,0.06033538,-0.03619181,-0.03282133,0.01078454,0.06667945,-0.01235847,0.08635456,-0.02615455,0.12121905,0.03852028,0.06550346,-0.03729383,0.00784031,0.05240401,-0.05353155,0.02334961,-0.0389286,-0.03613745,-0.00134422,0.01194908,-0.24282867,0.04577106,-0.00276962,0.07886979,0.01906855,-0.03035449,0.06400203,-0.05944442,0.00807716,0.01630698,-0.06205435,0.02828314,0.02711036,-0.07321843,-0.04341803,0.04482297,0.05391944,-0.01577127,0.04785276,-0.03693821,0.02512679,0.05033853,0.23151124,-0.04381007,0.05650668,-0.0648465,-0.05940742,-0.04922827,0.07602129,-0.01526525,0.02737365,-0.01393473,0.12756942,-0.01757769,0.01176667,0.07213312,-0.00079966,0.01082228,0.04912248,0.03410132,0.10929149,-0.03160399,0.02611558,-0.0332146,0.11310431,-0.00539535,0.07211176,-0.07666428,-0.0555037,0.06977051,-0.01867913,-0.00858499,0.01556584,0.00972767,0.01085368,0.0366016,-0.04177715,-0.0202159,-0.01965563,-0.01191112,0.01354994,-0.08773694,0.01575894,0.02034828,-0.03085273],"last_embed":{"hash":"1g0w2lq","tokens":476}}},"text":null,"length":0,"last_read":{"hash":"1g0w2lq","at":1768089432104},"key":"MIT Deep Learning Course.md###[Recurrent Neural Networks, Transformers, and Attention](https://www.youtube.com/watch?v=GvezxUdLrEk)#Intuition behind Self-Attention#{1}","lines":[29,73],"size":4540,"outlinks":[{"title":"Pasted image 20250314074421.png","target":"Pasted image 20250314074421.png","line":5,"embedded":true},{"title":"Pasted image 20250314075245.png","target":"Pasted image 20250314075245.png","line":8,"embedded":true},{"title":"Pasted image 20250314075755.png","target":"Pasted image 20250314075755.png","line":14,"embedded":true},{"title":"Pasted image 20250314080048.png","target":"Pasted image 20250314080048.png","line":19,"embedded":true},{"title":"Pasted image 20250314080220.png","target":"Pasted image 20250314080220.png","line":21,"embedded":true},{"title":"Pasted image 20250314080347.png","target":"Pasted image 20250314080347.png","line":24,"embedded":true},{"title":"Pasted image 20250314090053.png","target":"Pasted image 20250314090053.png","line":29,"embedded":true},{"title":"Pasted image 20250314091141.png","target":"Pasted image 20250314091141.png","line":39,"embedded":true},{"title":"Pasted image 20250314091330.png","target":"Pasted image 20250314091330.png","line":42,"embedded":true},{"title":"Pasted image 20250314091338.png","target":"Pasted image 20250314091338.png","line":44,"embedded":true}],"class_name":"SmartBlock","last_embed":{"hash":"1g0w2lq","at":1768089432104}},
