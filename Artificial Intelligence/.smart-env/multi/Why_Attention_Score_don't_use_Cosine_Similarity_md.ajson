
"smart_sources:Why Attention Score don't use Cosine Similarity.md": {"path":"Why Attention Score don't use Cosine Similarity.md","last_embed":{"hash":null},"embeddings":{},"last_read":{"hash":"bi9wux","at":1768089397308},"class_name":"SmartSource","last_import":{"mtime":1758374117930,"size":3881,"at":1768089397309,"hash":"bi9wux"},"blocks":{"###1. [[Cosine Similarity]]":[1,13],"###1. [[Cosine Similarity]]#{1}":[2,13],"###2. Role of $d_{k}$ in Attention Scaling":[14,24],"###2. Role of $d_{k}$ in Attention Scaling#{1}":[15,24],"###Summary: Why use $d_{k}$ Instead of Cosine Similarity":[25,32],"###Summary: Why use $d_{k}$ Instead of Cosine Similarity#{1}":[27,32],"###Impact of $d_{k}$":[33,40],"###Impact of $d_{k}$#{1}":[35,40]},"outlinks":[{"title":"Cosine Similarity","target":"Cosine Similarity","line":1}],"task_lines":[],"tasks":{},"codeblock_ranges":[]},
"smart_sources:Why Attention Score don't use Cosine Similarity.md": {"path":"Why Attention Score don't use Cosine Similarity.md","embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.03815112,-0.02455175,-0.00206451,-0.05487287,-0.01609517,-0.03701251,0.06901645,0.00392278,0.06657358,-0.05223901,0.0256048,-0.02145594,0.0127323,0.0640853,0.06036206,-0.01930127,-0.00774561,0.05895718,-0.09350877,-0.04402611,0.04299884,-0.00443141,0.05985046,-0.00384412,0.06747886,0.02835024,-0.04038519,-0.07099574,-0.0255099,-0.25746357,0.03855131,0.00774588,0.06841788,-0.01079186,-0.04936479,0.00616961,-0.03432084,0.01047638,-0.00697525,-0.0231077,0.0170003,0.05117196,0.02384058,-0.06141499,-0.07714304,-0.01719268,-0.07541092,-0.02172384,-0.02362109,0.00561048,0.01310547,-0.0791749,-0.00729473,0.00569354,0.06972443,0.14256532,0.02949783,0.02268554,0.035562,0.01358493,0.07384778,-0.00203734,-0.18415856,0.04835829,0.04337629,0.00709048,-0.00459156,-0.07924585,-0.03210216,0.06982432,-0.01125826,0.01466266,-0.00565337,0.00334807,0.02788757,-0.02928481,-0.0292213,-0.0064973,-0.03002556,-0.03008777,-0.00091442,0.06341004,-0.02689008,-0.02456975,0.01438383,0.00722487,-0.00388404,-0.04404693,0.03459845,-0.05176117,-0.01798516,-0.07085563,-0.02502954,-0.02835864,0.03840138,-0.02287344,0.03403116,0.01640201,-0.0702646,0.08041142,-0.01196018,0.04731712,-0.02377894,-0.04077156,0.0770914,-0.04174364,-0.03670049,-0.06062793,0.00789148,0.03439173,0.02501482,-0.03330174,-0.07026774,-0.0244211,-0.00841482,0.02237521,0.06234574,0.0498196,0.07139468,-0.04752764,0.02030066,0.02698567,0.0352303,0.0109404,0.00838241,-0.01232826,-0.00119314,0.00241096,0.01880077,-0.04243169,0.04798276,-0.03997812,-0.08918446,-0.00077949,-0.0438528,-0.00093175,0.02512836,-0.00780403,-0.00161895,0.00542042,0.04772973,-0.0257067,0.056015,-0.04387264,-0.02960579,0.15073569,-0.09004496,0.02432607,0.01668703,-0.02008161,-0.00069506,-0.00701766,-0.05810128,-0.04268178,-0.0397341,0.00846476,-0.00758907,-0.00529761,-0.03562903,-0.03111937,-0.02019479,0.0266314,-0.06622727,0.07733923,-0.00587083,-0.02877602,0.02393347,0.05046584,-0.00971831,0.00295158,0.04062749,-0.04600475,-0.00548046,0.07028084,0.05318069,-0.00410952,-0.08858444,-0.01055934,0.02191328,0.03977934,0.05246057,-0.05794415,-0.01658078,0.02679592,0.01126203,-0.02617978,-0.00127181,-0.04396253,0.02882722,0.01045814,-0.03225654,-0.00383303,-0.04976986,0.01338629,-0.09598148,0.02491415,0.01775131,-0.00063173,0.02881517,0.01146642,0.02731463,0.03024944,0.01938977,-0.02076438,0.00479042,0.01293526,0.04634237,-0.03693372,0.07046821,-0.0220756,-0.03020444,-0.06292903,-0.02748903,-0.01453196,-0.09695534,-0.01492236,0.0198644,0.11939982,0.00810888,0.10367437,0.00673665,-0.05628955,-0.07557537,-0.2262219,-0.01843656,0.03250873,-0.01343001,0.02999272,-0.04896291,0.02477792,0.04802882,0.03669627,0.06074363,0.04797886,0.00911299,-0.04089059,-0.0163933,-0.00966319,0.04496743,-0.01690277,0.07720773,0.00074767,-0.02497986,0.02427885,0.03972988,-0.00663902,-0.027307,0.02421499,-0.0405153,0.16864827,0.02221847,0.03478685,0.02713877,-0.03566376,-0.00562382,-0.00122289,-0.0277313,-0.0307388,0.00724587,0.01992347,-0.00107225,-0.05591813,-0.03121944,-0.0687326,-0.01041087,0.08120687,-0.05335706,-0.05716265,0.03568076,-0.01366336,0.03451806,0.02310023,0.09012861,0.03233539,-0.0684206,0.00898069,0.03931435,0.06831716,-0.09579132,-0.06633341,-0.00118268,-0.02939823,-0.00819899,-0.03224948,-0.04465609,0.06076217,-0.00083865,0.00078215,0.04771974,0.01879717,-0.00953763,0.02040222,0.05474994,-0.03046062,0.10955148,-0.01519479,0.00282978,0.01123291,-0.02375827,0.08047961,0.02120368,0.02599932,-0.00663232,0.04887938,-0.02219599,-0.00180454,-0.01947938,0.07854296,-0.00200309,0.08218871,-0.02982158,0.0191474,0.00570692,-0.02052293,-0.01306387,0.00629902,-0.06999673,0.00020533,0.03999955,-0.26796529,0.03203378,0.02152831,-0.00387348,0.01732207,-0.0121055,0.04377356,-0.10001226,-0.00529942,0.00137096,-0.00880616,0.04702165,0.02284437,-0.05855696,-0.05307613,0.01739376,0.02170942,-0.04003798,0.06182953,-0.02377476,-0.01389211,-0.01948453,0.21375047,-0.03584298,0.03216486,-0.08750343,-0.02578019,0.01331894,0.04205235,0.02634728,-0.00237688,0.05256639,0.09359154,-0.01841458,0.03253705,0.08120608,0.00795023,0.00538998,0.07793799,0.01099306,0.05376425,0.00506941,-0.03318857,-0.02545343,0.1456555,0.04229856,-0.01027253,-0.08580847,0.01130367,-0.01286485,-0.00899321,-0.0052899,0.03546727,0.0153594,0.01104007,0.02278168,-0.08932184,0.00995215,0.00203111,-0.02962247,0.01891662,-0.03483777,0.04026393,0.08993062,0.01117855],"last_embed":{"hash":"bi9wux","tokens":449}}},"last_read":{"hash":"bi9wux","at":1768089447147},"class_name":"SmartSource","last_import":{"mtime":1758374117930,"size":3881,"at":1768089397309,"hash":"bi9wux"},"blocks":{"###1. [[Cosine Similarity]]":[1,13],"###1. [[Cosine Similarity]]#{1}":[2,13],"###2. Role of $d_{k}$ in Attention Scaling":[14,24],"###2. Role of $d_{k}$ in Attention Scaling#{1}":[15,24],"###Summary: Why use $d_{k}$ Instead of Cosine Similarity":[25,32],"###Summary: Why use $d_{k}$ Instead of Cosine Similarity#{1}":[27,32],"###Impact of $d_{k}$":[33,40],"###Impact of $d_{k}$#{1}":[35,40]},"outlinks":[{"title":"Cosine Similarity","target":"Cosine Similarity","line":1}],"task_lines":[],"tasks":{},"codeblock_ranges":[],"last_embed":{"hash":"bi9wux","at":1768089447069}},"smart_blocks:Why Attention Score don't use Cosine Similarity.md###1. [[Cosine Similarity]]#{1}": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.03826605,-0.02543569,-0.00788708,-0.0536176,-0.00818856,-0.03958654,0.06185353,0.00351008,0.06149261,-0.0509307,0.02255346,-0.0199608,0.00904136,0.06097978,0.05708791,-0.03146266,-0.01052059,0.06192489,-0.08602696,-0.04196624,0.04171797,-0.00779787,0.05615082,-0.01138166,0.07425407,0.03845404,-0.04347768,-0.07548454,-0.02206838,-0.26033136,0.03737503,0.00965515,0.06479412,-0.00886335,-0.04799945,0.01600858,-0.03435282,0.01458073,-0.00920132,-0.02358907,0.00994076,0.04037358,0.03129017,-0.06212409,-0.07386216,-0.01525819,-0.07410388,-0.01605173,-0.01797694,0.00682775,0.00984177,-0.07354272,-0.01076794,0.00357565,0.06612555,0.14448833,0.02735629,0.02663793,0.02696785,0.02038766,0.07016081,-0.00879734,-0.18543416,0.05285306,0.04051617,0.00684877,-0.00151882,-0.07671147,-0.0330568,0.07718618,-0.01254188,0.01511378,-0.0145567,0.01267747,0.03054686,-0.03536561,-0.02172427,-0.00752447,-0.03181149,-0.02829165,0.00037498,0.05772336,-0.02623324,-0.01820051,0.01685993,-0.00902417,-0.00197797,-0.03318703,0.03072081,-0.04956149,-0.01623449,-0.06328426,-0.02456479,-0.0169466,0.04003925,-0.02238594,0.03741492,0.02020368,-0.06295117,0.07680066,-0.01001416,0.04799868,-0.03120963,-0.04665418,0.0788473,-0.03869901,-0.0446245,-0.0553111,0.01728432,0.02174358,0.01965545,-0.02225125,-0.07067375,-0.0247704,-0.01145403,0.02278085,0.05766172,0.04869627,0.07001146,-0.05541964,0.01212963,0.0174208,0.03538097,0.01952136,0.00678104,-0.01751146,-0.00251791,-0.00302806,0.02124938,-0.03533432,0.05547497,-0.04052748,-0.08959816,-0.00301451,-0.03828846,-0.00059615,0.02409514,0.00022569,-0.00585708,0.00796762,0.05068944,-0.03650017,0.05445455,-0.04427752,-0.02708932,0.15168579,-0.09600492,0.01958666,0.01157899,-0.01590063,-0.00301729,-0.01194065,-0.0585021,-0.04113369,-0.03555216,0.00528243,0.00118967,-0.00925997,-0.03445719,-0.03212884,-0.01358473,0.01591474,-0.07699618,0.07997231,0.00193489,-0.02603084,0.01719629,0.04713995,-0.00427598,0.01253478,0.03998658,-0.04823621,0.00281376,0.06338827,0.05485698,-0.01114538,-0.09037966,-0.00741722,0.01949118,0.03912383,0.05136615,-0.05248638,-0.02480291,0.03181899,0.01455852,-0.02071975,-0.01101608,-0.04703753,0.01859303,0.00806202,-0.02937715,-0.00650622,-0.06061361,0.01905508,-0.0892716,0.02580541,0.02359964,0.00726094,0.03141361,0.00656594,0.03243455,0.02731683,0.02726777,-0.02709002,-0.00457429,0.01652557,0.05365567,-0.04481287,0.0630933,-0.01592795,-0.02632001,-0.07741567,-0.03270356,-0.01490452,-0.09175577,-0.00503205,0.02334545,0.12713413,0.01611954,0.10833547,-0.00213452,-0.06115292,-0.06526762,-0.23034085,-0.01462846,0.02787778,-0.01257893,0.03784332,-0.05410041,0.01765957,0.04509502,0.02656181,0.05324205,0.04113109,0.00031909,-0.03009128,-0.01753381,-0.02335284,0.05429613,-0.01356685,0.08075564,0.00129568,-0.01820973,0.01515113,0.0277595,-0.0132623,-0.01797274,0.03368558,-0.04248762,0.17008151,0.02443114,0.04090781,0.02285867,-0.0299407,-0.00253631,0.00071582,-0.02345202,-0.02110238,0.01455171,0.01955103,0.00067474,-0.05665708,-0.03528972,-0.0616135,-0.00894507,0.08309096,-0.04969059,-0.05465652,0.03698174,-0.01605462,0.03541281,0.02360006,0.08911046,0.02756453,-0.05425153,0.01237669,0.04087492,0.07571051,-0.09333769,-0.06694141,0.00828842,-0.01857208,-0.01024339,-0.02581393,-0.04590976,0.06333039,0.00345662,0.00422525,0.052423,0.02591708,-0.01732186,0.02904722,0.05389539,-0.02890362,0.10907953,-0.01708633,0.0001469,0.01366826,-0.02393657,0.08845978,0.02387892,0.02655075,-0.01543155,0.04663303,-0.03162264,-0.00265874,-0.01860327,0.0789658,-0.00999874,0.08873524,-0.03415178,0.02786912,0.00961667,-0.01839968,-0.01248615,0.00412997,-0.06838901,-0.00159921,0.03651974,-0.26522565,0.03318086,0.02515738,-0.00345211,0.00996263,-0.01380679,0.04215211,-0.11418074,-0.02050906,0.0053179,-0.00357569,0.03820913,0.0273313,-0.05492786,-0.04860458,0.01902889,0.02340437,-0.0419801,0.05743771,-0.02201852,-0.01118944,-0.02402271,0.21067843,-0.03695311,0.02902411,-0.08418024,-0.02309029,0.01193505,0.03621841,0.02806796,-0.00590521,0.04991556,0.10113413,-0.01687463,0.03238507,0.08555429,0.00621739,0.00682418,0.08324569,0.00604926,0.04611071,0.00298975,-0.03536873,-0.02222863,0.1480307,0.04908736,-0.01589134,-0.07792813,0.01521868,-0.01430153,-0.01040917,0.00116826,0.02776209,0.00980621,0.0031347,0.01629926,-0.09283345,-0.00289126,0.00231966,-0.02742892,0.01760846,-0.03478692,0.04051865,0.08997145,0.0042539],"last_embed":{"hash":"1uupo2b","tokens":409}}},"text":null,"length":0,"last_read":{"hash":"1uupo2b","at":1768089447087},"key":"Why Attention Score don't use Cosine Similarity.md###1. [[Cosine Similarity]]#{1}","lines":[2,13],"size":1425,"outlinks":[],"class_name":"SmartBlock","last_embed":{"hash":"1uupo2b","at":1768089447087}},
"smart_blocks:Why Attention Score don't use Cosine Similarity.md###2. Role of $d_{k}$ in Attention Scaling#{1}": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.05999982,-0.01844355,0.02413471,-0.04437671,-0.05753607,-0.02489917,0.03501602,0.01824105,0.05643321,-0.05417195,0.04210009,-0.0328843,0.02309331,0.05996608,0.05018755,0.03123479,0.01715607,0.01506746,-0.09441692,-0.01988325,0.03851453,0.00629372,0.0352726,0.00293469,0.06760123,-0.01747732,-0.0364411,-0.10910095,-0.01708166,-0.26611897,0.02901568,0.00881913,0.07141556,0.00035445,-0.03481279,-0.020715,-0.02686198,0.01261231,-0.01651906,-0.00110439,0.01985627,0.0643076,0.00404824,-0.06347741,-0.03811804,-0.02377775,-0.07854857,-0.04783938,-0.03186072,0.0239742,0.00434058,-0.06872435,-0.0036647,0.01839162,0.04918749,0.08563721,0.01722837,0.02089397,0.08571308,0.01368446,0.05775931,0.02553836,-0.18407214,0.01001454,0.02297862,0.02319326,-0.02178123,-0.06379603,-0.04467408,0.07619648,-0.01389858,0.01626271,0.01418759,-0.00663383,0.04680755,-0.02768006,-0.06147005,-0.00192871,-0.01074587,0.02843123,-0.02514471,0.03927438,-0.05406724,-0.05680026,-0.00657064,0.04132572,0.01476352,-0.09345039,0.04542914,-0.03425581,-0.01047456,-0.07039304,-0.01116254,-0.05050409,-0.00816754,-0.00401729,0.02518675,0.03046714,-0.07919092,0.08534064,-0.00289037,0.02656654,-0.03290457,-0.01089065,0.02311729,-0.04293728,0.00642661,-0.05143796,-0.03116674,0.00826923,0.01375479,-0.03367677,-0.04241985,-0.01540449,0.0075459,0.01526318,0.04730583,0.03664785,0.0441171,-0.01064303,0.0692592,0.05032964,0.05679482,-0.01607414,0.0451066,0.01426885,-0.00976303,0.03076784,-0.0044166,-0.05190611,0.00386464,-0.07560715,-0.08227567,0.01179376,-0.03580052,-0.01325025,0.01721798,-0.00815976,0.00712736,0.00669334,-0.0005028,0.01953589,0.03621591,-0.04596153,-0.03742913,0.13940284,-0.04229351,0.03160029,0.05656479,-0.04369559,-0.04792294,-0.00120525,-0.04517025,-0.06528669,-0.02320971,0.0427278,-0.01652257,0.00707519,-0.07176622,-0.01563056,-0.03332218,0.04557776,-0.03947424,0.12739651,-0.04052396,0.00630371,0.02694711,0.04105591,-0.00183415,-0.02071525,0.03467283,-0.04542492,-0.03276815,0.05768785,0.03804293,-0.00075905,-0.1077013,-0.00885163,0.01960822,0.01487293,0.06645852,-0.05899105,0.0068743,0.02167065,0.0158847,-0.04046853,0.00407888,-0.03962854,0.05969853,-0.02417313,-0.04636332,0.02571883,-0.03069677,-0.02379163,-0.11501148,-0.0043384,-0.00155066,-0.01010674,0.01401586,0.02854236,0.01007006,0.02042289,0.00191242,0.00483095,0.03712318,0.01074373,0.00011756,-0.02804769,0.05931533,-0.00811995,-0.03888795,0.0057677,-0.00270223,-0.01577708,-0.06609073,0.00184606,0.02227121,0.0751328,-0.04894156,0.05633404,0.0462567,-0.02102133,-0.12182544,-0.24748543,-0.04438434,0.03174426,-0.0161249,0.01020445,-0.03973391,0.0666713,0.03851169,0.03502506,0.10489208,0.0474739,0.03906899,-0.06588264,-0.05482788,-0.00211697,0.02168966,-0.02311995,0.02649692,0.00157799,-0.03080301,0.05516751,0.06719759,0.01046389,-0.04518454,0.0450733,-0.0213757,0.16312219,0.00212401,0.03204061,0.02342281,0.00215085,0.00577299,-0.01479681,-0.04845738,-0.02257259,-0.02359436,0.00371415,-0.02229959,-0.04835138,-0.0195521,-0.0412299,-0.01021722,0.01692438,-0.05844778,-0.05572821,0.02562716,-0.02288002,0.07544209,0.00597108,0.10095974,0.03172615,-0.07119813,0.01338412,0.0075955,0.04346217,-0.07098596,-0.06767955,-0.00314929,-0.04454514,0.01691931,-0.02323377,-0.0519605,0.02841122,-0.02297172,0.00914507,0.03866523,0.01709135,0.00517358,0.01796175,0.03314016,-0.03992524,0.07112309,-0.00112967,0.01390767,0.03867997,-0.03413598,0.01024573,0.03736123,0.0252802,0.01062889,0.07399799,0.01953546,0.00902228,-0.00870863,0.06882437,0.00525605,0.07194815,0.03467395,-0.00047203,0.01920694,-0.03541161,-0.01616411,0.00671229,-0.0481468,0.04363392,0.02556907,-0.28247508,0.05486968,-0.00868894,-0.01286524,0.03577454,0.02974544,0.04919023,-0.06670078,-0.00483362,-0.01189383,-0.0094139,0.0848297,-0.01007091,-0.03932611,-0.02610878,0.01317241,0.0337357,-0.02156313,0.08956187,-0.03983326,0.00398059,0.03642978,0.21267106,-0.02258273,0.03108864,-0.06875269,-0.01016946,0.01825733,0.04805908,0.03165098,0.0002291,0.07282725,0.10323037,-0.01183596,0.01718817,0.08102294,0.00165673,0.01446766,0.06017017,0.03999076,0.09474366,-0.01151189,-0.04402432,-0.04577525,0.11567999,0.02744043,0.01920858,-0.10095628,-0.02681546,-0.02216571,0.00349875,-0.0165232,0.03932582,0.0137506,0.0168836,0.06459031,-0.05451331,0.03566155,0.00000471,-0.03471997,-0.00095247,-0.01791819,-0.00583238,0.08071885,0.0008854],"last_embed":{"hash":"nxjdkw","tokens":175}}},"text":null,"length":0,"last_read":{"hash":"nxjdkw","at":1768089447102},"key":"Why Attention Score don't use Cosine Similarity.md###2. Role of $d_{k}$ in Attention Scaling#{1}","lines":[15,24],"size":489,"outlinks":[],"class_name":"SmartBlock","last_embed":{"hash":"nxjdkw","at":1768089447102}},
"smart_blocks:Why Attention Score don't use Cosine Similarity.md###Summary: Why use $d_{k}$ Instead of Cosine Similarity": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.06091021,-0.01488978,0.02157706,-0.06113273,-0.01828407,-0.03894037,0.03006441,0.01374272,0.04253701,-0.04996028,0.05604096,-0.02981505,0.04794228,0.03450345,0.03272115,-0.01347819,0.0231985,0.0453349,-0.07318042,-0.03739899,0.0275699,-0.01325167,0.05845392,-0.03476022,0.07286379,0.02132164,-0.01800528,-0.06705651,-0.04069231,-0.27726611,0.04338687,0.01501442,0.04689564,0.00008363,-0.05958894,-0.02143899,-0.02298783,0.010527,-0.03435254,0.00695527,-0.00209314,0.03016618,0.01140927,-0.0320017,-0.07291793,-0.03321686,-0.09946059,-0.02134754,-0.0199376,0.0366897,0.00970927,-0.07173795,0.01337166,0.00336218,0.05233395,0.08588587,0.02469896,0.0265091,0.07067008,0.02369856,0.07274213,-0.01169293,-0.18737946,0.02760693,0.0371622,0.02837924,-0.00267386,-0.08195831,-0.06647324,0.03519505,-0.00979439,0.04374019,-0.00065397,0.02667265,0.05764411,-0.00390972,-0.04626206,-0.03431176,-0.00656661,-0.00212861,-0.01168902,0.03798601,-0.05176217,-0.05786574,-0.00233067,-0.04237922,0.01312149,-0.03340935,0.03515342,-0.04266422,-0.02020348,-0.0476923,0.00442835,-0.03331188,0.00991619,0.01166076,0.03997818,0.04354999,-0.09484282,0.04415384,-0.01710987,0.04673894,-0.0779661,-0.04502914,0.04311718,-0.0351638,0.00664552,-0.02640161,0.0268334,0.03372331,0.01798861,-0.0258016,-0.04489689,-0.04466048,0.03514998,-0.00079638,0.02693908,0.01054205,0.05484531,-0.02407199,0.02081253,0.02762334,0.03518075,0.00114363,0.05027822,0.00580508,-0.00315473,0.03067959,0.01237576,-0.00508565,0.01353834,-0.07385754,-0.08178157,-0.00104439,-0.02894113,-0.02021263,0.00445653,0.02141864,-0.00780642,0.01736653,0.01282758,-0.01479471,0.02806873,-0.0533683,-0.03348691,0.13319328,-0.07447116,-0.00878991,0.04391611,-0.0433232,0.01073873,-0.01244325,-0.06218172,-0.06129659,-0.03562096,0.00340582,-0.0091126,0.03091934,-0.03960546,-0.01854531,-0.02805684,0.00953386,-0.04428715,0.06838478,-0.04526315,-0.01402945,0.02420633,0.04607499,-0.01767938,-0.01025386,0.0418165,-0.05448226,-0.02094229,0.05323317,0.06462308,-0.01134498,-0.08258329,0.00561057,0.00955257,0.02231504,0.03660359,-0.03478624,-0.0035699,0.02829454,0.02868231,-0.04087416,0.01040534,-0.03193308,0.01461134,-0.0147057,-0.04820773,-0.01168133,-0.02384171,0.00393054,-0.08069097,0.0105033,0.0004751,0.00679818,-0.0057384,0.02805326,0.04481633,0.03221444,0.02064789,-0.01171045,0.0148925,0.01872604,0.01852112,-0.07522687,0.09228792,-0.01984076,-0.04258136,-0.01247759,0.00526716,-0.00695603,-0.08609481,-0.01762266,0.00540831,0.09035789,0.00383796,0.08083305,0.02395288,-0.01267476,-0.12855932,-0.26635715,-0.01169934,0.02862469,-0.01704026,0.01019503,-0.0397094,0.03775769,0.02919689,0.01920743,0.07700521,0.04015437,0.03180394,-0.06079382,-0.03676986,-0.02387779,0.00819336,-0.02845098,0.03570815,-0.00830559,-0.01988795,0.03462986,0.0390278,-0.01244108,-0.04772935,0.02850499,-0.03828011,0.16843092,0.01697977,0.03370179,0.01197467,0.00351018,0.03439952,0.00698942,-0.03090264,-0.04706801,0.00217354,0.0218019,-0.00959195,-0.03002145,-0.03458977,-0.04320455,-0.00742572,0.03386889,-0.04012952,-0.05171387,0.0346514,0.00369715,0.0832617,-0.01101892,0.10625345,0.02063615,-0.02153605,0.027066,0.03590765,0.08540118,-0.10189756,-0.04246083,-0.00938502,-0.00836931,0.02668601,0.0145973,-0.0415115,0.04152731,-0.00068599,0.00004306,0.02976301,0.00572873,-0.00061422,0.01607669,0.05753868,-0.05065999,0.10566029,-0.00026977,0.02541986,0.05087005,-0.03037325,0.03258165,0.04602991,0.02398495,-0.01235953,0.11053663,0.0031502,0.00655649,-0.0506225,0.0255977,0.01714726,0.08615621,0.00922033,0.02054742,-0.0112711,-0.04476603,-0.050508,0.02328968,-0.06604835,0.05265751,0.0432082,-0.28391683,0.04383772,0.00005022,-0.03864463,0.007506,0.02594391,0.03506148,-0.06638794,0.00008113,-0.01143211,-0.01083902,0.06623301,-0.01791073,-0.04468954,-0.04728295,0.02185956,0.02184727,-0.01678227,0.09851974,-0.03440728,0.00781175,0.01786274,0.22774825,-0.02398289,0.02752148,-0.02468137,0.00700629,0.03725449,0.0781533,0.03165209,-0.01442282,0.05254694,0.10503323,-0.00706861,0.01512957,0.07417702,-0.00705917,0.00809075,0.05869222,0.03152114,0.04148818,-0.00298658,-0.02348186,-0.02863525,0.12804554,-0.01086549,0.00561971,-0.09786199,0.01028926,-0.0379074,-0.01993793,-0.0042639,0.02722551,-0.01050909,0.0167899,0.06175561,-0.05918513,0.04071236,0.01851882,-0.03927005,-0.00179647,-0.00603453,0.03485331,0.13658427,0.00839198],"last_embed":{"hash":"2jq4e2","tokens":320}}},"text":null,"length":0,"last_read":{"hash":"2jq4e2","at":1768089447111},"key":"Why Attention Score don't use Cosine Similarity.md###Summary: Why use $d_{k}$ Instead of Cosine Similarity","lines":[25,32],"size":852,"outlinks":[],"class_name":"SmartBlock","last_embed":{"hash":"2jq4e2","at":1768089447111}},
"smart_blocks:Why Attention Score don't use Cosine Similarity.md###Summary: Why use $d_{k}$ Instead of Cosine Similarity#{1}": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.06133324,-0.0139663,0.02177314,-0.06240688,-0.01803816,-0.0384009,0.02973621,0.01462076,0.0458376,-0.05016616,0.05646075,-0.03082735,0.04702759,0.03245748,0.03074144,-0.01416836,0.02181701,0.04427886,-0.07650069,-0.0395529,0.02971978,-0.01318964,0.05431239,-0.03698084,0.07450607,0.01988328,-0.01795292,-0.0666714,-0.03914202,-0.27647185,0.04300021,0.01312176,0.04885458,0.00044286,-0.06121647,-0.02188623,-0.02195035,0.01117282,-0.03669873,0.00585285,-0.00074479,0.0312745,0.01028682,-0.03283853,-0.07420401,-0.03517761,-0.10103764,-0.02056232,-0.02051571,0.03762849,0.00704698,-0.07025041,0.01255972,0.00366979,0.05373178,0.08481091,0.0253807,0.02760898,0.07128558,0.02225493,0.07326214,-0.01271121,-0.18502125,0.02551089,0.03750948,0.02930562,-0.00447923,-0.08262123,-0.06574152,0.036586,-0.01061728,0.04236521,-0.00063792,0.02657715,0.0581211,-0.00534589,-0.04749746,-0.03560215,-0.00736978,-0.00085993,-0.0108461,0.03673476,-0.05164489,-0.05881489,-0.0020779,-0.04016107,0.01367285,-0.03397268,0.03910224,-0.04211473,-0.01775613,-0.04982018,0.00524728,-0.03158873,0.00728003,0.01473867,0.04135044,0.04376434,-0.09222779,0.04337715,-0.01867951,0.04913228,-0.07948643,-0.04415431,0.03964933,-0.03594683,0.01056578,-0.02785607,0.0266235,0.03099741,0.0194644,-0.02462583,-0.04629453,-0.04687725,0.03408906,-0.00126268,0.02659356,0.00924622,0.05542432,-0.02314702,0.02278626,0.02842539,0.03502324,0.00225092,0.0522182,0.00597901,-0.00543452,0.03207807,0.01142898,-0.00650555,0.01375048,-0.07124135,-0.08105994,-0.00192051,-0.02634656,-0.01997004,0.00463487,0.02211737,-0.00877005,0.0182695,0.01327742,-0.01173367,0.02542723,-0.05093498,-0.03403585,0.13517125,-0.06915689,-0.00914961,0.04466479,-0.04517031,0.00849224,-0.01150322,-0.0613825,-0.06381606,-0.03256967,0.00268578,-0.00998275,0.03000146,-0.03914999,-0.01992655,-0.03236119,0.01062575,-0.04314351,0.06562772,-0.04760041,-0.01094321,0.02607927,0.04555592,-0.02106806,-0.01259764,0.04410521,-0.05248671,-0.02173688,0.05211427,0.06486177,-0.01216919,-0.0826131,0.0053948,0.00961856,0.02172679,0.04014065,-0.03557073,-0.0069111,0.02870229,0.03089356,-0.04034469,0.00968311,-0.03077174,0.01380518,-0.01445749,-0.04841049,-0.0082852,-0.01944451,0.00150817,-0.0805366,0.00941572,-0.00127876,0.00855,-0.0089771,0.02881002,0.0426649,0.03335344,0.02039962,-0.01067362,0.01519794,0.01757659,0.01656059,-0.0730832,0.09020772,-0.01930018,-0.04578191,-0.01106839,0.00284922,-0.005803,-0.08410525,-0.01843823,0.00621754,0.08877764,0.0024761,0.07971804,0.02596078,-0.01620163,-0.12772301,-0.26736975,-0.01105731,0.02898591,-0.01677937,0.00984294,-0.04099406,0.03814967,0.02850297,0.02034451,0.0786822,0.03904757,0.02763254,-0.06019686,-0.03921093,-0.02518764,0.00874379,-0.02930734,0.03444759,-0.00913398,-0.01991831,0.03261065,0.0381452,-0.0132639,-0.04812497,0.02873335,-0.03734116,0.16751766,0.01914769,0.03367089,0.01221912,0.00364855,0.03482393,0.00791795,-0.03057227,-0.04215818,-0.00077268,0.02165249,-0.00915466,-0.03215234,-0.03489732,-0.04156621,-0.0064336,0.03244617,-0.03754542,-0.05261637,0.03555436,0.00323498,0.08265387,-0.0098238,0.10582309,0.02237649,-0.02049663,0.02610235,0.03509173,0.08630683,-0.10116863,-0.0416233,-0.0082473,-0.01005505,0.02612654,0.01415003,-0.03898998,0.04125014,-0.00071052,0.00122529,0.02847365,0.00534614,-0.00087879,0.01544002,0.05661828,-0.05063,0.10586836,-0.00153516,0.02627507,0.05671534,-0.02702927,0.03272569,0.04648466,0.02142819,-0.01121349,0.11273862,0.00056847,0.00718743,-0.04939979,0.02540347,0.01623159,0.08567179,0.01122201,0.01909889,-0.01141313,-0.04670019,-0.04946458,0.02321877,-0.06424683,0.05198488,0.04067317,-0.28179118,0.04598176,-0.00589539,-0.03890361,0.00680007,0.02885268,0.0361969,-0.06574653,0.00076262,-0.01421046,-0.01414733,0.06518988,-0.01823439,-0.04714591,-0.04819649,0.02109196,0.02604004,-0.0142915,0.0991633,-0.03507644,0.00723857,0.02288415,0.22804637,-0.02622199,0.02533601,-0.02373142,0.01028153,0.03731067,0.08040005,0.03153672,-0.01656328,0.05135066,0.1082871,-0.00866934,0.01411739,0.07509048,-0.00627099,0.00635547,0.05525547,0.03089813,0.04478446,-0.00257162,-0.02392072,-0.02786399,0.13042417,-0.00886098,0.00792628,-0.10003123,0.01262554,-0.04139968,-0.02142213,-0.00257745,0.02498475,-0.00906285,0.0177863,0.06133026,-0.05777096,0.0434631,0.02069361,-0.03981169,-0.0028862,-0.00525927,0.03720206,0.13400286,0.00811513],"last_embed":{"hash":"1hpdkht","tokens":318}}},"text":null,"length":0,"last_read":{"hash":"1hpdkht","at":1768089447121},"key":"Why Attention Score don't use Cosine Similarity.md###Summary: Why use $d_{k}$ Instead of Cosine Similarity#{1}","lines":[27,32],"size":791,"outlinks":[],"class_name":"SmartBlock","last_embed":{"hash":"1hpdkht","at":1768089447121}},
"smart_blocks:Why Attention Score don't use Cosine Similarity.md###Impact of $d_{k}$": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.04275528,-0.03728385,0.02367318,-0.05458704,-0.01464928,-0.00079102,0.0065598,0.00168953,0.04605108,-0.06795149,0.04566627,-0.01440685,0.02822983,0.07774316,0.02766091,-0.01714262,0.03794098,0.02847957,-0.09460258,-0.02540588,0.00577222,0.00621222,0.06680409,-0.02126215,0.01989541,-0.02513168,-0.03915996,-0.06523389,-0.07416117,-0.27184647,0.02858271,0.02229903,0.06802806,0.00866056,-0.0548471,0.01066745,-0.02673731,0.01633352,-0.01409145,0.01262635,0.00208381,0.05771537,-0.0127758,-0.04718152,-0.06183807,-0.03099858,-0.08114771,-0.05238232,-0.04576831,0.00966934,0.00185783,-0.10964656,0.0200534,0.00955063,0.03746668,0.06755828,0.03296559,0.06163363,0.06707311,0.04070345,0.03973296,0.01146961,-0.20706411,0.01015974,0.01074354,0.02741201,-0.03549659,-0.03757281,-0.04307256,0.0412869,-0.00463721,0.04635993,0.01400684,0.01955158,0.03701374,0.0210882,-0.04159836,-0.00618199,0.03113121,-0.02282478,-0.00125138,0.04903378,-0.05180228,-0.08599333,0.00288959,-0.01507615,0.01104003,-0.07485285,0.04428199,-0.05149802,-0.00651999,-0.04508239,-0.00202574,-0.03587414,0.02912361,0.02944896,0.02980746,0.02679218,-0.11575243,0.07991,-0.02342547,0.04945344,-0.05839921,-0.04664941,0.03877553,-0.03296985,0.01184346,-0.02203523,0.02055196,0.01356098,0.02575071,-0.02774235,-0.05420948,-0.01587206,0.01858619,0.04279936,0.0612018,0.01941647,0.03341466,-0.00297633,0.03534695,0.02673144,0.05690882,-0.02366927,0.00054968,0.00068719,-0.0059685,0.0717179,0.02485756,-0.01446072,0.02319873,-0.07960513,-0.09080807,0.01362948,-0.01938509,-0.02148714,-0.0055501,0.01618317,-0.01989643,0.05233742,0.01550057,0.01406783,0.04977397,-0.0582559,-0.07051583,0.16930428,-0.03558493,0.03662816,0.03719852,-0.08002448,0.00703522,0.0183898,-0.0643712,-0.04285667,-0.02320885,0.03693566,-0.00671545,0.01288762,-0.05668748,-0.02638008,-0.02453577,0.00880488,-0.05528928,0.08324639,-0.03591995,-0.01048912,-0.00762006,0.0221695,-0.00911715,-0.01152178,0.01242722,-0.05934159,-0.00747251,0.05488115,0.03766587,-0.00907303,-0.08747919,-0.02431581,-0.01170842,0.02799738,0.0376343,-0.04224206,-0.00041047,0.04026888,-0.00253673,0.00001865,0.00865266,-0.02133012,0.03895299,-0.01821894,-0.07322926,-0.0086393,-0.01831911,-0.0187694,-0.07651879,-0.00178276,-0.03062178,-0.01829815,-0.00939857,0.04059631,0.01093784,0.02756163,0.03892688,-0.0231732,0.01609087,0.02672935,-0.00877436,-0.03981341,0.10330206,-0.03176119,-0.06092716,0.00170637,0.00942946,-0.02345869,-0.04354258,-0.00581702,0.0395414,0.09473228,-0.03354189,0.04994527,0.03205417,0.00608904,-0.09807477,-0.2542966,-0.00385137,0.028484,-0.01757489,0.00326142,-0.04355,0.04762037,0.03555407,0.04766091,0.0977303,0.07548092,0.01563125,-0.04476145,-0.05899226,-0.01110097,0.00017863,-0.02940047,0.01953655,-0.00916551,0.01484059,0.04990155,0.04332744,0.02635369,-0.0657183,0.0516713,-0.02075722,0.15141843,0.00661617,0.02499525,-0.01094824,-0.00000992,0.04820823,-0.0018273,-0.06231958,0.01102687,0.01525731,0.04099924,0.00033052,-0.05915853,-0.01929307,-0.05707145,0.00720866,0.03482557,-0.08329567,-0.05235662,0.00303315,0.01350309,0.05105179,-0.02946604,0.09279442,0.02031165,-0.02654956,0.04397585,0.01466728,0.06164937,-0.07530787,-0.0583289,0.01222698,-0.03571016,-0.01211955,0.00690016,-0.0701936,0.02530077,-0.01504494,0.00117509,0.01651573,0.00230054,0.0003315,-0.0025607,0.03563473,-0.05107272,0.09795254,0.00875595,0.04576376,0.04694311,-0.0322421,0.01197938,0.03325681,0.01507017,-0.01293842,0.09103251,0.01951328,0.00583722,-0.01755236,0.04512503,0.02512558,0.07846757,-0.02101098,0.02200121,-0.01309534,-0.03576479,-0.04940847,-0.02622088,-0.05448674,0.05634714,0.02170831,-0.25850359,0.06165753,0.02932753,-0.01352892,0.03804714,0.03528877,0.04927861,-0.06513706,0.00976407,-0.02579942,-0.0013181,0.0586106,-0.00307143,-0.03376102,-0.05116354,0.05654628,0.0403128,-0.01362058,0.09244234,-0.03426118,-0.00045167,0.02727218,0.17981502,-0.01627691,0.0120468,-0.05620706,-0.01814818,0.0244657,0.08035342,0.04883842,-0.01097926,0.06146642,0.13728376,0.03133902,0.00660569,0.08497429,-0.02087271,0.00198892,0.04404719,0.03691853,0.08603591,-0.01670068,0.00408514,-0.02707729,0.10487058,-0.03054158,0.01790269,-0.10576575,-0.02650257,-0.04084692,-0.00068389,-0.02010128,0.02198281,0.01655586,0.03368552,0.05757743,-0.01994689,0.00877946,-0.01455182,-0.02790108,0.00185381,-0.03225576,-0.01428729,0.09593502,0.02366494],"last_embed":{"hash":"1i0md7m","tokens":406}}},"text":null,"length":0,"last_read":{"hash":"1i0md7m","at":1768089447132},"key":"Why Attention Score don't use Cosine Similarity.md###Impact of $d_{k}$","lines":[33,40],"size":1036,"outlinks":[],"class_name":"SmartBlock","last_embed":{"hash":"1i0md7m","at":1768089447132}},
"smart_blocks:Why Attention Score don't use Cosine Similarity.md###Impact of $d_{k}$#{1}": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.04366725,-0.03736116,0.0262116,-0.05140392,-0.01614799,-0.00139753,0.00598721,0.00300599,0.04597106,-0.06868892,0.04785969,-0.01216387,0.02722124,0.07522695,0.02724982,-0.02030329,0.03770241,0.02971088,-0.09474192,-0.02518818,0.00661938,0.0041275,0.06785094,-0.02373404,0.02255743,-0.02475328,-0.03934197,-0.05969923,-0.07344119,-0.2725637,0.02952495,0.02347839,0.06872581,0.00723727,-0.05612333,0.01203223,-0.02952979,0.01753655,-0.01553243,0.01092565,0.0027462,0.06004861,-0.01058225,-0.04902101,-0.06294308,-0.03140952,-0.08078561,-0.05180894,-0.04839726,0.00937863,0.00220834,-0.10987914,0.02094325,0.01189394,0.03718847,0.06502341,0.03300394,0.06496089,0.06813435,0.0420183,0.03945808,0.01072244,-0.20724361,0.01113166,0.00711996,0.0274816,-0.03711187,-0.03544876,-0.04280559,0.03986163,-0.00547884,0.04551698,0.01520967,0.0184362,0.03647403,0.0215295,-0.04234328,-0.00449384,0.02897295,-0.02144095,0.00255953,0.04782393,-0.05586861,-0.08643182,0.00161737,-0.01427146,0.01179913,-0.07923714,0.04506159,-0.04937848,-0.00636629,-0.04546819,-0.00247378,-0.03641392,0.02898553,0.02912393,0.03174518,0.02704416,-0.11282524,0.08085473,-0.0212091,0.05058842,-0.05898329,-0.0473379,0.03860197,-0.03355011,0.01061433,-0.02307957,0.02096332,0.01212056,0.02765985,-0.02677802,-0.0564298,-0.01733038,0.01633889,0.04100026,0.06035811,0.02030865,0.0325492,-0.00310177,0.03604742,0.02854194,0.0580972,-0.02173677,0.00101309,-0.00133502,-0.00323943,0.07324387,0.02406157,-0.01474242,0.0245751,-0.07915533,-0.08688173,0.01494606,-0.02144473,-0.02072109,-0.00826714,0.01698914,-0.02070836,0.0539691,0.01646897,0.01454556,0.04945981,-0.05936931,-0.07143573,0.17125271,-0.03513621,0.035521,0.03987914,-0.08290999,0.00813609,0.01824585,-0.06181029,-0.04122733,-0.02511571,0.03687002,-0.00844465,0.01202227,-0.05624583,-0.02829343,-0.02581326,0.00849171,-0.05276402,0.08364808,-0.03482405,-0.00788385,-0.00762976,0.02147347,-0.00857024,-0.01192622,0.01325508,-0.05805485,-0.00593704,0.05371858,0.03607776,-0.01191887,-0.08560563,-0.02460713,-0.01187164,0.02668779,0.03844195,-0.04111002,-0.00049944,0.03978672,-0.00354189,0.00117127,0.00372527,-0.01823193,0.03922189,-0.01640767,-0.07427356,-0.00706815,-0.01773901,-0.02262138,-0.07567666,-0.00429259,-0.03403961,-0.01547458,-0.01217262,0.04037535,0.01286668,0.02905541,0.03763395,-0.02298673,0.01272686,0.02449569,-0.00888064,-0.04017206,0.10041505,-0.0331457,-0.06265158,0.00170121,0.0115251,-0.02384458,-0.04394845,-0.00385379,0.04076943,0.09302764,-0.0345978,0.05104648,0.03252692,0.00625426,-0.09527586,-0.25471693,-0.00497067,0.0273135,-0.0156699,0.00430973,-0.04533634,0.04744184,0.03129936,0.04780064,0.09497274,0.07319056,0.01384658,-0.04388674,-0.05727775,-0.00921908,0.00017738,-0.02912213,0.02185263,-0.00879964,0.01599611,0.04783897,0.04463977,0.02424328,-0.06558511,0.05040212,-0.02063745,0.14760228,0.00406954,0.02490244,-0.01058579,0.00081722,0.04988839,-0.00102453,-0.05824765,0.01507691,0.01811681,0.04204936,-0.00063565,-0.06180776,-0.01961928,-0.05611431,0.00810662,0.0345222,-0.08191795,-0.04978224,0.00281047,0.01305957,0.05130685,-0.03149644,0.09542921,0.02065656,-0.02450829,0.04418741,0.01171126,0.06582687,-0.07511695,-0.05860849,0.01461147,-0.03313969,-0.01448094,0.00726934,-0.07072837,0.02292623,-0.01428402,0.00285102,0.01543246,0.00194185,-0.00072418,-0.00213557,0.03410191,-0.04951493,0.09866816,0.01013787,0.04514493,0.04777024,-0.03123536,0.0097235,0.0327676,0.01346239,-0.01116121,0.09176039,0.01893208,0.00741733,-0.01685256,0.04336079,0.02281813,0.07792094,-0.02183986,0.0232593,-0.01302503,-0.03659837,-0.05080527,-0.02686117,-0.05250994,0.05646333,0.02237867,-0.25870532,0.06289537,0.0284085,-0.01418614,0.03781239,0.03479178,0.046553,-0.06644979,0.01161013,-0.02862056,-0.00340857,0.05915432,-0.00266921,-0.03179794,-0.05244031,0.05347149,0.04490941,-0.01207156,0.09297279,-0.03298965,0.00239987,0.02630556,0.17981592,-0.0168376,0.01122606,-0.05894462,-0.01647804,0.02481036,0.07909389,0.04675502,-0.00987817,0.06157764,0.13799594,0.03187966,0.00647713,0.08618326,-0.02394575,-0.0018818,0.0427239,0.03992368,0.08671566,-0.01483805,0.00237688,-0.02570661,0.10744681,-0.0277545,0.01866869,-0.10792125,-0.02702687,-0.04257664,-0.00067124,-0.01885214,0.01876161,0.01755691,0.03632964,0.0570656,-0.02138641,0.00714958,-0.01278775,-0.02772835,0.00046323,-0.02988725,-0.01589947,0.09379046,0.02307631],"last_embed":{"hash":"1adhfue","tokens":404}}},"text":null,"length":0,"last_read":{"hash":"1adhfue","at":1768089447147},"key":"Why Attention Score don't use Cosine Similarity.md###Impact of $d_{k}$#{1}","lines":[35,40],"size":1010,"outlinks":[],"class_name":"SmartBlock","last_embed":{"hash":"1adhfue","at":1768089447147}},
