
"smart_sources:Log Loss Function in NN Model for Multiple Traning Example.md": {"path":"Log Loss Function in NN Model for Multiple Traning Example.md","last_embed":{"hash":null},"embeddings":{},"last_read":{"hash":"26uid4","at":1768089396812},"class_name":"SmartSource","last_import":{"mtime":1758374117638,"size":2541,"at":1768089396812,"hash":"26uid4"},"blocks":{"#":[2,13],"###**2. Intuition Behind the Loss Function**":[14,45],"###**2. Intuition Behind the Loss Function**#{1}":[16,32],"###**2. Intuition Behind the Loss Function**#**Loss When $y = 1$: $L = -\\log(a)$**":[33,39],"###**2. Intuition Behind the Loss Function**#**Loss When $y = 1$: $L = -\\log(a)$**#{1}":[35,39],"###**2. Intuition Behind the Loss Function**#**Loss When $y = 0$: $L = -\\log(1 - a)$**":[40,45],"###**2. Intuition Behind the Loss Function**#**Loss When $y = 0$: $L = -\\log(1 - a)$**#{1}":[42,44],"###**2. Intuition Behind the Loss Function**#**Loss When $y = 0$: $L = -\\log(1 - a)$**#{2}":[45,45]},"outlinks":[{"title":"2","target":"i","line":7},{"title":"2","target":"i","line":7},{"title":"2","target":"i","line":12},{"title":"2","target":"i","line":20},{"title":"2","target":"i","line":21},{"title":"2","target":"i","line":22},{"title":"2","target":"i","line":22},{"title":"2","target":"i","line":23},{"title":"2","target":"i","line":23},{"title":"2","target":"i","line":26},{"title":"2","target":"i","line":27},{"title":"2","target":"i","line":28},{"title":"2","target":"i","line":28},{"title":"2","target":"i","line":29},{"title":"2","target":"i","line":29}],"task_lines":[],"tasks":{},"codeblock_ranges":[]},
"smart_sources:Log Loss Function in NN Model for Multiple Traning Example.md": {"path":"Log Loss Function in NN Model for Multiple Traning Example.md","embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.014089,0.0138934,-0.0161403,-0.08215895,0.00022359,0.08409087,0.01689124,0.01347756,0.09289854,-0.01621197,-0.00678206,-0.04054999,0.0093214,0.05149624,0.01761535,0.00950223,-0.04745795,0.03614801,-0.07031238,-0.00708668,0.10785027,-0.03041345,0.01343627,-0.02568523,0.04281465,0.00332811,-0.00306139,-0.03047492,-0.04708681,-0.26463795,0.03162672,-0.045088,-0.02054447,-0.04986647,0.02545709,0.01825845,-0.03408288,0.0302658,-0.02492046,0.0067812,0.03797104,0.06988562,0.0123851,-0.04470089,0.03522889,-0.09267534,-0.0332693,-0.02367166,-0.0626979,-0.02334882,0.00676795,0.02641189,0.00585446,0.0536794,0.03761808,0.02876423,-0.00010157,0.03081966,0.02602096,0.04315872,0.06697042,0.03312313,-0.1922061,0.0206348,0.04022501,0.029347,-0.03552193,-0.04775692,0.0201629,0.07661314,-0.03185859,-0.04472654,0.0125627,0.03151459,-0.04555504,-0.00163054,0.00419485,-0.00826037,-0.0661018,-0.03273461,0.0243669,0.01464674,-0.02393379,-0.03813685,0.00929574,-0.00603274,0.03921929,-0.06697682,0.04014575,-0.04936279,-0.00129472,0.02196194,-0.04707765,0.04235926,0.00284785,0.03989297,0.06721061,0.07703426,0.00802649,0.1157659,0.01450176,0.0121614,0.00554655,-0.06289524,0.00935827,-0.08035894,-0.05496363,-0.04389768,-0.03878307,-0.01985083,0.04037718,0.02930398,0.01209318,-0.03841172,-0.018317,-0.01194829,0.0723642,0.04670399,0.00235606,0.02422898,0.00889612,0.02559666,0.10451947,-0.01507415,0.04671498,-0.00128473,-0.01839725,0.07486089,0.02556655,-0.01752862,0.024366,-0.01277726,-0.00997848,-0.00149505,0.00515386,-0.00525869,0.00425601,0.01603679,-0.04140649,0.04893696,0.00324493,-0.02709099,-0.01752676,-0.06809397,-0.05881755,0.10604396,-0.00040588,-0.01095867,-0.03521625,-0.03667765,-0.00815543,0.04421324,-0.01869247,-0.09187472,0.02336306,0.0296132,0.01503455,0.0425623,-0.09272755,0.01059454,-0.04647617,-0.06807297,0.02955653,0.04846856,0.00074691,0.02639217,0.04118613,0.04442209,0.01644228,-0.10313652,0.03905965,0.04199593,-0.02043137,-0.07746922,0.00581373,0.05348562,-0.06753944,-0.07804327,0.00497437,-0.00127767,-0.04185696,-0.06658927,-0.02722194,0.01246401,0.06384284,0.00417818,-0.03858129,-0.04264885,0.02219483,0.04134871,-0.0186255,-0.07793113,-0.01410921,0.02648412,-0.03358458,-0.01106023,-0.0264763,0.00162158,-0.01060708,-0.02363579,0.07762765,0.0522249,0.02058521,-0.00581664,-0.05357987,0.03145568,-0.03529855,-0.03753599,0.00131966,0.0359614,-0.05517448,0.01388408,0.02815627,0.01956573,0.00281383,0.01172135,0.07082654,0.05953257,0.0121727,0.03901394,-0.00431452,-0.04446108,-0.0665668,-0.19062623,-0.12262639,0.01590206,-0.02531566,0.06133003,-0.10283038,0.00104638,0.00396851,0.00499161,0.06184738,0.06657851,0.05171959,-0.04852176,-0.00203131,0.01250712,0.0185822,0.02758912,0.01015136,-0.07767572,0.00049804,-0.02468063,0.05205723,0.04022019,-0.05059281,0.01734758,-0.0211279,0.09785724,-0.03088732,0.11271077,0.02764464,-0.00775959,0.04056216,-0.01032846,0.05338267,0.06071225,0.0604158,-0.00537054,-0.01272969,-0.01164307,-0.08211542,-0.0142049,0.02932949,0.03029564,-0.06427285,-0.07709875,0.00120132,-0.05224536,-0.03918,-0.09163947,0.07500837,0.08197065,0.02211493,0.06520206,-0.01758278,0.03848933,-0.05487032,-0.05857965,-0.04220805,-0.04011929,0.01033478,-0.02070553,-0.05141983,0.00492472,-0.07952854,0.07057425,-0.03404882,-0.01527578,-0.02073682,-0.02178838,-0.04909676,0.00881386,0.10591953,-0.00511987,-0.03821706,0.05340925,-0.00590964,0.01889485,-0.02395506,-0.06532582,0.00509101,0.05556772,-0.07686981,0.05662195,0.00765568,0.06193835,0.03826371,0.08837226,-0.01421121,-0.00144551,0.01116369,-0.04372223,-0.02114016,0.01339862,-0.03840275,0.00859036,0.01513892,-0.24588226,-0.00430869,0.01579054,0.0507181,-0.04203507,-0.00112011,0.03543682,-0.02755158,-0.0077672,-0.00622797,0.04481927,0.01779123,0.031806,-0.00684722,0.05489948,0.01928536,-0.01291065,-0.07177082,0.07129663,0.00121057,0.03494315,0.04533736,0.15822953,-0.01925819,0.0795124,0.03440922,-0.03256781,0.03926508,0.06570181,-0.0340425,0.05177478,-0.00540829,0.15358269,-0.0400699,0.05927554,0.03971808,0.0258022,0.01289652,0.04264335,-0.05662827,0.10564774,-0.00908616,-0.00490009,-0.01613073,0.1754553,0.02793851,-0.02602962,-0.04187699,-0.05427129,0.04166136,-0.00319456,0.05669147,0.04067102,0.01651334,-0.00165023,0.02279927,-0.03559845,-0.06143879,-0.00610416,-0.05803965,0.02285185,-0.03775347,0.00047012,-0.04866613,-0.07958697],"last_embed":{"hash":"26uid4","tokens":451}}},"last_read":{"hash":"26uid4","at":1768089430154},"class_name":"SmartSource","last_import":{"mtime":1758374117638,"size":2541,"at":1768089396812,"hash":"26uid4"},"blocks":{"#":[2,13],"###**2. Intuition Behind the Loss Function**":[14,45],"###**2. Intuition Behind the Loss Function**#{1}":[16,32],"###**2. Intuition Behind the Loss Function**#**Loss When $y = 1$: $L = -\\log(a)$**":[33,39],"###**2. Intuition Behind the Loss Function**#**Loss When $y = 1$: $L = -\\log(a)$**#{1}":[35,39],"###**2. Intuition Behind the Loss Function**#**Loss When $y = 0$: $L = -\\log(1 - a)$**":[40,45],"###**2. Intuition Behind the Loss Function**#**Loss When $y = 0$: $L = -\\log(1 - a)$**#{1}":[42,44],"###**2. Intuition Behind the Loss Function**#**Loss When $y = 0$: $L = -\\log(1 - a)$**#{2}":[45,45]},"outlinks":[{"title":"2","target":"i","line":7},{"title":"2","target":"i","line":7},{"title":"2","target":"i","line":12},{"title":"2","target":"i","line":20},{"title":"2","target":"i","line":21},{"title":"2","target":"i","line":22},{"title":"2","target":"i","line":22},{"title":"2","target":"i","line":23},{"title":"2","target":"i","line":23},{"title":"2","target":"i","line":26},{"title":"2","target":"i","line":27},{"title":"2","target":"i","line":28},{"title":"2","target":"i","line":28},{"title":"2","target":"i","line":29},{"title":"2","target":"i","line":29}],"task_lines":[],"tasks":{},"codeblock_ranges":[],"last_embed":{"hash":"26uid4","at":1768089430068}},"smart_blocks:Log Loss Function in NN Model for Multiple Traning Example.md#": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.01355052,0.01200479,-0.01401195,-0.08188453,-0.00025783,0.08538305,0.0152468,0.01785263,0.09325542,-0.01598202,-0.00632131,-0.03525777,0.01073313,0.05045029,0.0176028,0.00994293,-0.04770094,0.0334345,-0.07136658,-0.00412595,0.10503613,-0.03211142,0.01040856,-0.02612413,0.04043205,0.00188617,-0.00398874,-0.02948323,-0.04863557,-0.26297596,0.03401355,-0.04710554,-0.01452487,-0.04776572,0.02973817,0.01797485,-0.0309812,0.02860162,-0.02588375,0.00443125,0.03805741,0.06939353,0.01683247,-0.04079354,0.03326046,-0.09758175,-0.03119522,-0.02642269,-0.06715805,-0.02291668,0.00160478,0.02471805,0.00437656,0.04989747,0.03508792,0.02934074,-0.00009461,0.02919251,0.02982324,0.04140846,0.06172726,0.03230727,-0.19490379,0.01771355,0.03798858,0.0281622,-0.03468573,-0.05149074,0.02067041,0.0735115,-0.03376296,-0.04289117,0.01868411,0.03240621,-0.04380521,-0.00035176,0.00112022,-0.0138011,-0.06287166,-0.03470998,0.02341631,0.01549589,-0.02168876,-0.03801017,0.00908323,-0.00450004,0.04141359,-0.06860536,0.04376559,-0.0502752,-0.00211843,0.02168989,-0.05061062,0.04430871,0.00404275,0.04194108,0.06678452,0.07914446,0.00783398,0.11302827,0.01209764,0.01319783,0.00276746,-0.06457677,0.01120976,-0.08002851,-0.05303363,-0.04458823,-0.03993428,-0.02132776,0.04131051,0.03223082,0.01283427,-0.03818903,-0.01726448,-0.01753116,0.07143255,0.04794554,0.00037629,0.02155342,0.00704224,0.02519838,0.10262522,-0.0158755,0.04452067,0.00155172,-0.0160658,0.07336555,0.0232878,-0.01588721,0.02388008,-0.01870177,-0.01129297,-0.00007962,0.00257815,-0.00902203,0.00423112,0.02160775,-0.04144916,0.04966333,0.00648317,-0.02502282,-0.02006958,-0.06792062,-0.06042317,0.10989038,-0.00117333,-0.00717605,-0.0333088,-0.04138917,-0.00385982,0.05011544,-0.02157985,-0.09074944,0.02200741,0.03248111,0.01228738,0.0451382,-0.09193111,0.0080778,-0.04650649,-0.06526325,0.02933105,0.04948695,0.00111994,0.02865678,0.03882493,0.04460153,0.01552214,-0.09351689,0.0433956,0.04176217,-0.02111157,-0.07429545,0.00710251,0.05428998,-0.06657209,-0.07328269,0.0068468,-0.00151528,-0.04257255,-0.06697049,-0.02373348,0.01120361,0.06766183,0.00462533,-0.03621401,-0.04285474,0.03000183,0.04135723,-0.01710573,-0.07711654,-0.01703706,0.02594269,-0.03275711,-0.01013712,-0.0253175,0.00438622,-0.00829857,-0.02637231,0.07552996,0.05479246,0.02166102,-0.00936209,-0.05072605,0.03292568,-0.03917024,-0.03796712,0.00448705,0.03031366,-0.05602905,0.00891775,0.0285134,0.01662029,0.0007871,0.01517708,0.07414382,0.05404358,0.00960985,0.04419036,-0.00798886,-0.04404326,-0.06501842,-0.1894597,-0.12409383,0.01841967,-0.02740228,0.06297071,-0.103671,-0.00055984,0.00443279,0.00590056,0.06158784,0.06717797,0.05019568,-0.04935789,-0.00335764,0.01468463,0.01637637,0.02974055,0.0091798,-0.07721286,0.00563399,-0.0260246,0.04883604,0.03638158,-0.04560314,0.01369716,-0.02437988,0.09695004,-0.03248051,0.11116958,0.02638004,-0.01357935,0.03960162,-0.01233726,0.05185759,0.05520883,0.06690665,-0.00952631,-0.01362023,-0.01647686,-0.08370797,-0.01568676,0.02932657,0.02923082,-0.06485254,-0.07450326,0.00414824,-0.05151229,-0.03783564,-0.09745434,0.07270294,0.08011298,0.02424653,0.06645685,-0.02051927,0.04019083,-0.0575304,-0.05806883,-0.04599116,-0.0392432,0.00832825,-0.0188753,-0.04944054,0.0042547,-0.07916198,0.06761796,-0.03945918,-0.0121891,-0.02455367,-0.01967916,-0.04849463,0.00912065,0.10654908,-0.00185194,-0.03771394,0.05717373,-0.00873236,0.02104489,-0.02772739,-0.06279543,0.00536397,0.05534138,-0.07426915,0.06337751,0.00787442,0.0625793,0.03846877,0.08804954,-0.01168599,-0.00109365,0.01467352,-0.04270922,-0.0201933,0.01033388,-0.03980286,0.00822857,0.01820561,-0.24690241,0.00023653,0.01264285,0.05359021,-0.04126655,-0.00574136,0.03544071,-0.02892826,-0.00915295,-0.00743483,0.0437824,0.01869756,0.0319214,-0.00886842,0.05348479,0.01489873,-0.01175303,-0.07360395,0.07158135,0.00025381,0.03435512,0.04270421,0.15612982,-0.02017971,0.08065195,0.02895796,-0.0273162,0.0392002,0.06567577,-0.035099,0.05295659,-0.00522404,0.15829736,-0.0390018,0.05954192,0.04023253,0.02375071,0.01215602,0.04111708,-0.05231268,0.111164,-0.00602704,-0.00880309,-0.01582487,0.17660426,0.0293938,-0.02177157,-0.0421771,-0.04940128,0.04583641,-0.00138275,0.05421488,0.04056988,0.01921974,-0.00231464,0.02191609,-0.03579798,-0.06197486,-0.00654742,-0.05731716,0.01940467,-0.03602942,0.00077567,-0.04751854,-0.07977539],"last_embed":{"hash":"170z00m","tokens":439}}},"text":null,"length":0,"last_read":{"hash":"170z00m","at":1768089430088},"key":"Log Loss Function in NN Model for Multiple Traning Example.md#","lines":[2,13],"size":1013,"outlinks":[{"title":"2","target":"i","line":6},{"title":"2","target":"i","line":6},{"title":"2","target":"i","line":11}],"class_name":"SmartBlock","last_embed":{"hash":"170z00m","at":1768089430088}},
"smart_blocks:Log Loss Function in NN Model for Multiple Traning Example.md###**2. Intuition Behind the Loss Function**": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.03946571,-0.00128148,-0.0297021,-0.06624936,-0.02911968,0.08153894,0.00808226,0.00844431,0.10071298,-0.02952302,0.012507,-0.01628556,0.04188013,0.04152209,-0.01686341,-0.0161348,-0.09799626,0.03947412,-0.08455077,-0.01973341,0.1246512,-0.00155899,-0.00897477,-0.01524432,0.03209269,0.00808284,0.01263125,-0.03882369,-0.02609736,-0.24546374,0.03566678,-0.03939947,-0.02476105,-0.06647722,0.01050975,-0.00183185,-0.03161375,0.03476177,-0.01670481,0.03850441,0.05532846,0.08177231,-0.01544901,-0.03760599,0.02468789,-0.05525997,-0.03817165,-0.05869526,-0.04214687,-0.03180663,-0.00341057,0.03432918,-0.00593704,0.04801534,0.04393055,0.02485476,0.01934207,0.04780373,0.00255485,0.06569415,0.07312818,0.0155668,-0.18639123,0.06578126,0.04419087,0.00345732,-0.03717584,-0.01928153,0.00972072,0.12504144,-0.03625759,-0.04564957,-0.01298572,0.05572467,-0.06100527,-0.0113944,0.03878742,-0.00203477,-0.06928023,-0.02089836,0.02379351,-0.00576578,-0.03568822,-0.02916605,-0.02036476,-0.00940028,0.03464443,-0.08649471,0.01127869,-0.03915904,0.02767351,0.03275094,-0.05039228,0.02242547,-0.02696236,0.02409576,0.06779008,0.0765941,-0.02055908,0.11902425,0.00600189,0.02972689,-0.01939886,-0.03564432,0.00493723,-0.03410167,-0.057447,-0.02775086,-0.00227347,-0.0445683,0.01789933,0.00754732,0.00571992,-0.06681277,0.01066337,0.01793063,0.08081374,0.03885707,-0.0208613,0.01986905,0.02362694,0.04379984,0.07784884,0.00277287,0.03897017,0.01722113,-0.02365815,0.07245361,0.04145169,0.02140047,0.03206054,0.0017392,0.00202763,0.0263501,0.01304221,-0.00667583,-0.02204042,0.02079226,-0.02728171,0.03515764,0.00601659,-0.01557795,-0.02115727,-0.05739323,-0.014015,0.07522723,0.02818046,-0.01113352,-0.01890419,-0.05782557,0.0097835,0.03546995,-0.01114027,-0.06545612,0.01190794,0.0154298,0.01525353,0.00384552,-0.0740428,0.01993614,-0.05545434,-0.04897106,0.00295643,0.00875723,-0.01149435,0.02316293,0.03787884,0.01450568,0.04273551,-0.11702894,-0.00612625,0.02826879,0.01135536,-0.10975642,0.02013506,0.05252317,-0.0729221,-0.07703194,-0.00519154,0.02367984,-0.03152781,-0.05630738,-0.0187573,0.01396441,0.01960236,0.01370306,-0.04659187,-0.04402859,0.02960867,0.05942084,-0.01757125,-0.05497662,-0.0268051,0.01189166,-0.07783137,-0.02683661,-0.03022168,-0.03181633,-0.00472771,-0.00606413,0.09290969,0.01765998,-0.02063754,0.00310634,-0.07525466,0.01995305,0.02180051,-0.05760105,-0.00592186,0.04752117,-0.01975915,0.0308147,0.0204981,0.00810123,0.01599164,0.02900121,0.0703379,0.07481856,0.03915358,0.01335478,0.03924214,-0.05081705,-0.02844033,-0.19636884,-0.08751404,0.02056854,-0.04145025,0.05270834,-0.06341492,-0.00340583,0.00268363,0.0102356,0.06448286,0.04538957,0.02774957,-0.04802126,-0.00515677,-0.01589179,0.0500187,0.00631056,-0.02192557,-0.02645667,0.00349156,-0.02464352,0.01731165,-0.00038029,-0.07532938,0.0076773,-0.00985346,0.12051252,-0.02813902,0.1090471,0.00092277,0.00621515,0.01126351,0.01472431,0.08917679,0.07006009,0.06970421,-0.03289443,-0.01114354,-0.00951789,-0.04921608,0.00249316,0.02244531,0.04968059,-0.04147764,-0.0922861,0.00337856,-0.07036516,-0.01297015,-0.05302559,0.08863913,0.11451982,0.0100094,0.07290477,-0.00135632,0.06515337,-0.04669694,-0.02960896,-0.04617454,-0.0484165,0.00871596,-0.03948234,-0.04163638,0.01716691,-0.08341188,0.07416242,-0.00054037,-0.01928194,-0.00779624,-0.0183091,-0.04424286,0.00752077,0.0901226,-0.04224382,-0.01520628,0.0626658,-0.00292229,0.00331298,-0.0006671,-0.05915781,-0.00685894,0.04063853,-0.12603508,0.06156272,-0.00215141,0.08996629,0.01980343,0.04685195,-0.025041,-0.00804336,0.00204429,-0.03813137,-0.02608855,0.04699445,-0.03902297,0.00319508,-0.03146943,-0.24641894,0.01115154,-0.01407935,0.07003996,-0.06236035,0.0297853,0.0056719,0.03031788,-0.02190489,-0.00370583,0.01447842,0.02188339,0.03765154,0.00085556,0.04168672,0.01732845,-0.00477326,-0.06351396,0.07305895,0.01685744,0.07152876,0.01770603,0.15298645,-0.05783015,0.06040083,0.05786733,-0.05415934,0.03232726,0.0802716,-0.01450454,0.05596301,0.00189452,0.12468676,-0.07721902,0.05189266,0.01571113,0.01215277,-0.00405551,0.04692503,-0.07860031,0.06527452,-0.02857697,0.03445239,-0.01447158,0.18032224,0.00946222,-0.03977048,-0.04055458,-0.0409606,0.0359552,-0.05075664,0.07391746,0.04187621,-0.02403362,0.00154631,0.0342205,-0.02548417,-0.03632211,-0.01365585,-0.04745268,0.04412793,-0.03123332,0.03479901,-0.04905307,-0.06817046],"last_embed":{"hash":"1hprtv6","tokens":463}}},"text":null,"length":0,"last_read":{"hash":"1hprtv6","at":1768089430106},"key":"Log Loss Function in NN Model for Multiple Traning Example.md###**2. Intuition Behind the Loss Function**","lines":[14,45],"size":1525,"outlinks":[{"title":"2","target":"i","line":7},{"title":"2","target":"i","line":8},{"title":"2","target":"i","line":9},{"title":"2","target":"i","line":9},{"title":"2","target":"i","line":10},{"title":"2","target":"i","line":10},{"title":"2","target":"i","line":13},{"title":"2","target":"i","line":14},{"title":"2","target":"i","line":15},{"title":"2","target":"i","line":15},{"title":"2","target":"i","line":16},{"title":"2","target":"i","line":16}],"class_name":"SmartBlock","last_embed":{"hash":"1hprtv6","at":1768089430106}},
"smart_blocks:Log Loss Function in NN Model for Multiple Traning Example.md###**2. Intuition Behind the Loss Function**#{1}": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.03835521,0.00413476,-0.03568933,-0.07416912,-0.03110103,0.08169672,0.00620046,0.0064791,0.09284244,-0.03664674,0.01436365,-0.02332626,0.04485506,0.04090676,-0.01462519,-0.02183248,-0.09164708,0.04127521,-0.082675,-0.02127701,0.12699769,-0.00203469,-0.0031023,-0.01118615,0.03342038,0.01123262,0.01217183,-0.03888089,-0.02791648,-0.24502842,0.03421449,-0.04360021,-0.02225339,-0.05745536,0.01709242,0.00037443,-0.03553901,0.03105977,-0.02535233,0.03584663,0.06006415,0.0829331,-0.01161381,-0.03957493,0.02218266,-0.05895825,-0.03522742,-0.05502141,-0.03688699,-0.03596839,0.00119459,0.0381057,-0.00837772,0.05401326,0.05131723,0.02097074,0.0229057,0.05752622,0.00491029,0.06197133,0.08296934,0.01239413,-0.17850067,0.06172001,0.04617441,0.0069657,-0.03539808,-0.02266604,0.00943786,0.12296328,-0.033684,-0.05087046,-0.01507425,0.05118157,-0.06561281,-0.01846536,0.03620761,0.00141423,-0.06638826,-0.02328025,0.02350615,-0.00913719,-0.0293005,-0.03037858,-0.01934473,-0.00745786,0.02645594,-0.08637618,0.00995926,-0.0408416,0.02880244,0.02876371,-0.04500463,0.02778767,-0.02427266,0.02409783,0.06523244,0.07202855,-0.02441654,0.11752787,0.01248723,0.02951947,-0.0224737,-0.03565226,0.00131744,-0.0346523,-0.05586215,-0.03160539,0.00624789,-0.04657785,0.01540113,0.01430344,0.00912678,-0.06778156,0.01134264,0.02481131,0.07725447,0.04140684,-0.02022119,0.02349491,0.02702199,0.04252288,0.07821429,-0.00627674,0.03989233,0.01371966,-0.02107763,0.06503827,0.04456023,0.02211774,0.03036642,0.0057137,0.00466087,0.02422135,0.01074479,-0.0082519,-0.02400302,0.02322841,-0.02554684,0.03051437,0.00522643,-0.01826642,-0.02362202,-0.05483651,-0.00758398,0.0790654,0.03242791,-0.01051276,-0.02267108,-0.05538794,0.00653245,0.03396622,-0.01430666,-0.06744717,0.00698011,0.01428218,0.01686145,0.00267221,-0.07924532,0.02138835,-0.05389125,-0.04463332,0.00375969,0.00781643,-0.00550574,0.0223908,0.03741394,0.00750405,0.0358875,-0.11208815,-0.00905415,0.02421504,0.01298985,-0.11075328,0.02318523,0.05026365,-0.07089764,-0.07931654,-0.00798557,0.03116507,-0.0302328,-0.05673558,-0.01474792,0.0143869,0.02266367,0.01331735,-0.05077101,-0.0507194,0.0260173,0.05940549,-0.02019219,-0.04798852,-0.03244111,0.01382393,-0.07668801,-0.02912832,-0.02965704,-0.02822076,-0.00470368,0.00118426,0.0993026,0.02251725,-0.01765796,0.00365829,-0.07436647,0.01627092,0.0190624,-0.06062519,-0.01005966,0.05375983,-0.02420662,0.03277691,0.01618742,0.00583365,0.01574784,0.02567391,0.06974958,0.06842421,0.04022074,0.01409289,0.0389113,-0.05067277,-0.02274702,-0.20232734,-0.08638708,0.02008815,-0.04718002,0.05525883,-0.06878709,-0.00200262,0.00205545,0.00701166,0.06083103,0.04744903,0.02734936,-0.04996159,0.002919,-0.01408564,0.0533959,0.00966945,-0.01871236,-0.02152063,-0.00078618,-0.02801605,0.01686514,0.00090379,-0.07818656,0.01238829,-0.01365368,0.12019073,-0.02459679,0.111145,-0.00740216,0.01153717,0.01059978,0.01169467,0.08189676,0.06967526,0.06266253,-0.03814175,-0.01016392,-0.00538892,-0.04795971,0.00139709,0.01962818,0.05315027,-0.04077918,-0.08482978,0.00630429,-0.07245808,-0.02276229,-0.04772446,0.08981182,0.11317849,0.0167634,0.06906176,0.00314121,0.0688124,-0.04973303,-0.03228601,-0.04627877,-0.0455169,0.00429672,-0.0446938,-0.04075658,0.01617607,-0.08094905,0.07250716,0.00414237,-0.02122934,-0.00683481,-0.01969812,-0.0456411,0.0057469,0.08700871,-0.0429092,-0.02058231,0.05805215,0.00063761,0.00379897,0.00129215,-0.05894289,-0.01112625,0.03361562,-0.12634388,0.05728944,-0.00411814,0.08644744,0.02528998,0.04600601,-0.0256142,-0.00790114,-0.0083698,-0.0409894,-0.01907155,0.05216111,-0.03798292,-0.00073596,-0.02906896,-0.24548469,0.01016964,-0.00788495,0.06522593,-0.06565441,0.03206341,0.00335497,0.03016021,-0.02218445,-0.01252971,0.01383679,0.02285024,0.03713648,0.00408401,0.04347812,0.0240271,-0.00406415,-0.06344175,0.07883671,0.01636339,0.07725039,0.02230539,0.15532826,-0.06094476,0.05942199,0.06270628,-0.05167316,0.03258688,0.08064166,-0.01430512,0.0540381,0.00393804,0.13317789,-0.07474168,0.0513284,0.00872634,0.00842174,-0.00244862,0.0501562,-0.07256165,0.06968425,-0.03410116,0.02850334,-0.01876857,0.18077675,0.00913079,-0.04004147,-0.03481279,-0.04090155,0.03195099,-0.04609996,0.07843386,0.04501994,-0.01807988,0.01117413,0.03453412,-0.03341207,-0.03809259,-0.02014025,-0.0400957,0.0376088,-0.02936696,0.03432728,-0.04599104,-0.0624241],"last_embed":{"hash":"1n5kvvw","tokens":421}}},"text":null,"length":0,"last_read":{"hash":"1n5kvvw","at":1768089430124},"key":"Log Loss Function in NN Model for Multiple Traning Example.md###**2. Intuition Behind the Loss Function**#{1}","lines":[16,32],"size":1003,"outlinks":[{"title":"2","target":"i","line":5},{"title":"2","target":"i","line":6},{"title":"2","target":"i","line":7},{"title":"2","target":"i","line":7},{"title":"2","target":"i","line":8},{"title":"2","target":"i","line":8},{"title":"2","target":"i","line":11},{"title":"2","target":"i","line":12},{"title":"2","target":"i","line":13},{"title":"2","target":"i","line":13},{"title":"2","target":"i","line":14},{"title":"2","target":"i","line":14}],"class_name":"SmartBlock","last_embed":{"hash":"1n5kvvw","at":1768089430124}},
"smart_blocks:Log Loss Function in NN Model for Multiple Traning Example.md###**2. Intuition Behind the Loss Function**#**Loss When $y = 1$: $L = -\\log(a)$**": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.06949286,0.00122765,0.01171811,-0.05366207,-0.03384594,0.06982389,0.01371323,0.00954875,0.10261325,-0.01239782,0.02463564,-0.02569708,0.02218105,0.04700954,0.00455182,-0.00962449,-0.10578203,0.03560189,-0.0656447,-0.03344029,0.11801644,0.00401362,-0.01062857,-0.01674791,0.03956327,-0.00696609,-0.00679131,-0.03407286,-0.00808939,-0.24975939,0.01485756,-0.02932736,-0.04606355,-0.06842452,-0.00472827,0.01886994,-0.02815583,0.04425365,-0.00375407,0.03533492,0.04840746,0.07117245,-0.01491494,-0.04214371,0.01223275,-0.05789614,-0.03934174,-0.03869313,-0.04368192,-0.01784643,-0.00539151,0.03965957,0.01281932,0.02270624,0.04974721,0.02188641,0.01108295,0.02622009,-0.00725134,0.06386548,0.05000908,0.02272753,-0.1888551,0.05302203,0.06875224,0.03218254,-0.0298299,-0.00551261,0.01823686,0.12149797,-0.01828743,-0.05015698,-0.0145495,0.05861879,-0.04026218,0.02631073,0.04325379,-0.01389805,-0.06531698,-0.03033037,0.03990274,0.00560177,-0.03567246,-0.02085143,-0.02183996,0.0081296,0.04540246,-0.06640285,0.00424611,-0.04094774,0.01804329,0.0384324,-0.04931652,0.00774449,-0.03740461,0.02277207,0.07175472,0.06673259,-0.00215039,0.12336701,0.00543083,0.00119581,0.02347713,-0.03226293,0.00592036,-0.04741629,-0.04391281,-0.04685776,-0.02245294,-0.02819562,0.02512958,0.00218605,0.00969469,-0.05528235,-0.00915834,-0.00110219,0.06436874,0.05048768,-0.0282872,0.00657187,0.0265202,0.0426675,0.10064102,0.00779251,0.03908831,0.00422261,-0.01886796,0.09339673,0.02900887,0.01084056,0.0359214,-0.01512554,-0.01527634,0.01067937,0.01708389,-0.01052359,-0.00600328,0.00860696,-0.04804648,0.05992525,0.00121645,-0.01168886,-0.01887604,-0.05458496,-0.03043792,0.06036485,0.03225621,-0.0365767,-0.02284351,-0.04368462,0.00741005,0.03126741,0.01226326,-0.06373517,0.02286599,0.01490582,-0.00273306,0.0318989,-0.07241592,0.0258782,-0.07668555,-0.07856674,-0.00068949,0.04120918,-0.02680035,0.01049278,0.03568068,0.04200758,0.04648174,-0.10495372,0.01122779,0.0293726,-0.01380163,-0.11182617,0.03331568,0.0542359,-0.06416646,-0.06671549,0.01019336,0.0129335,-0.00416907,-0.06782299,-0.0232013,0.02295227,0.03791014,0.01072684,-0.04590309,-0.01692188,0.02324827,0.06587661,-0.02656454,-0.07538201,-0.01343246,0.00406818,-0.05921762,-0.02337825,-0.04663755,-0.0221386,-0.0202389,-0.02380009,0.09647817,0.01525253,-0.00761754,-0.0024001,-0.07163569,0.00547141,0.03234014,-0.04945609,0.00139632,0.04556296,-0.03473692,0.01903212,0.06854302,0.00484894,0.01942181,0.03112233,0.05356561,0.07664435,0.02135284,0.01135716,0.01689103,-0.07021427,-0.03329224,-0.22656353,-0.09260517,0.02573621,-0.02082012,0.06120675,-0.06756742,-0.0191452,-0.00742401,0.01131195,0.0854252,0.02919791,0.01442408,-0.01440879,-0.02594136,0.00453123,0.05237377,-0.01349673,-0.01143412,-0.04358313,-0.01279091,-0.02369854,0.01953874,0.00617099,-0.08947438,0.01276333,0.00565926,0.1208825,-0.0138013,0.11312266,0.0077023,0.00413621,0.01723787,0.02174213,0.08327169,0.06096302,0.06699732,0.00552057,0.00805653,0.01673345,-0.06636199,0.0014142,0.0319095,0.03763272,-0.03141569,-0.09470918,0.00825661,-0.0765518,-0.00165395,-0.05445595,0.08277793,0.1078749,0.00595451,0.07266159,-0.00579499,0.04023144,-0.04553694,-0.05623895,-0.03957213,-0.03736335,0.01831296,-0.02648197,-0.05595065,-0.00725065,-0.0970429,0.10087651,-0.02940992,-0.00555389,-0.04026844,-0.02257676,-0.0361613,0.00401837,0.09121269,-0.01755041,-0.00641334,0.03398899,0.0153271,-0.01189186,-0.00694055,-0.08735602,-0.01608842,0.04381819,-0.10272571,0.04597135,0.01341158,0.06598707,0.0209735,0.04438848,-0.02957645,-0.00227446,0.00270417,-0.07230675,-0.06354217,0.01424042,-0.03592701,0.02477338,-0.03476365,-0.24162529,-0.01272212,0.00100057,0.05690223,-0.04040046,0.0315442,0.00715629,0.01856035,-0.0344311,0.00802437,0.01613641,0.02366233,0.04129447,0.00962889,0.04899785,0.01146378,0.00482257,-0.0596838,0.06106617,0.01588019,0.05351264,0.04213675,0.16433068,-0.03450319,0.07293119,0.03926958,-0.04896938,0.01031083,0.07969318,-0.00946176,0.04950341,0.01062659,0.11091298,-0.05480037,0.05193248,0.03706298,0.00557038,0.0062315,0.05214142,-0.09616314,0.03412254,0.01725491,0.0191647,0.00035663,0.15118951,0.01420525,-0.04911775,-0.05094662,-0.03112398,0.04234233,-0.0268413,0.06912646,0.0442026,-0.01840441,0.00272856,0.05377669,-0.0106289,-0.04319487,-0.00885418,-0.05869691,0.04350278,-0.03272313,0.0413607,-0.04799937,-0.08013732],"last_embed":{"hash":"1gkei43","tokens":119}}},"text":null,"length":0,"last_read":{"hash":"1gkei43","at":1768089430142},"key":"Log Loss Function in NN Model for Multiple Traning Example.md###**2. Intuition Behind the Loss Function**#**Loss When $y = 1$: $L = -\\log(a)$**","lines":[33,39],"size":235,"outlinks":[],"class_name":"SmartBlock","last_embed":{"hash":"1gkei43","at":1768089430142}},
"smart_blocks:Log Loss Function in NN Model for Multiple Traning Example.md###**2. Intuition Behind the Loss Function**#**Loss When $y = 0$: $L = -\\log(1 - a)$**": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.07077496,0.00227602,0.01173177,-0.05346417,-0.03364307,0.06966,0.01254298,0.00958097,0.1018699,-0.00900141,0.02774932,-0.02727407,0.02174596,0.05056823,0.00071718,-0.00866613,-0.10424665,0.03512875,-0.06744945,-0.03398063,0.11772199,0.00446214,-0.00941098,-0.01977686,0.04233049,-0.00747048,-0.00636294,-0.03316199,-0.00765163,-0.25065821,0.01213241,-0.03131141,-0.04406361,-0.06725781,-0.00284936,0.01745518,-0.02637646,0.04707117,-0.00383513,0.034389,0.0468017,0.07041053,-0.01623297,-0.04312759,0.01134211,-0.05764259,-0.04039095,-0.03965959,-0.04262797,-0.02071441,-0.00521413,0.04060786,0.01023781,0.02283374,0.04707856,0.02127264,0.01019461,0.02201975,-0.00579445,0.06393587,0.0495388,0.02287967,-0.18925278,0.05174772,0.07226666,0.0312754,-0.03245832,-0.00762893,0.01699357,0.11968488,-0.01473817,-0.0510443,-0.01279356,0.05819348,-0.04067929,0.02582604,0.04656731,-0.01142786,-0.06468417,-0.03282802,0.03758375,0.00477539,-0.0352455,-0.02075797,-0.01927667,0.00899417,0.04517346,-0.06555712,0.00429184,-0.03820447,0.01910134,0.04053149,-0.04951673,0.00562727,-0.03735347,0.02706011,0.06831364,0.06534229,-0.0049935,0.12092395,0.00828463,0.00100174,0.02463521,-0.03140503,0.00602509,-0.04672177,-0.04626981,-0.04776539,-0.02470449,-0.03057875,0.02176747,-0.00077417,0.01231714,-0.05474962,-0.00887388,-0.00028573,0.06332886,0.05270655,-0.02772428,0.00677139,0.02459069,0.03809489,0.10133547,0.0104852,0.04019846,0.00552704,-0.01815649,0.09513592,0.02467364,0.01234029,0.03530966,-0.01535451,-0.0146104,0.01057492,0.0151343,-0.01079338,-0.00736285,0.00957727,-0.04727134,0.05701964,0.00148886,-0.01185245,-0.02169622,-0.05271449,-0.03167958,0.06227753,0.02913832,-0.03830633,-0.02000114,-0.04503219,0.01005857,0.02945057,0.01364189,-0.06536452,0.02440015,0.01429593,-0.00250077,0.03083049,-0.07524548,0.02829033,-0.07734793,-0.08040878,-0.00463928,0.04401471,-0.02659904,0.01253635,0.03709072,0.04074854,0.04672933,-0.10274121,0.0124426,0.02864643,-0.01224141,-0.11168328,0.03729368,0.05266117,-0.06303365,-0.06975967,0.01099437,0.00990154,-0.00522861,-0.06684968,-0.02139401,0.0258272,0.03909011,0.01221638,-0.0457752,-0.01891091,0.02383408,0.06330833,-0.02761201,-0.07954966,-0.01434492,0.00642762,-0.05782562,-0.02228337,-0.0436664,-0.02054409,-0.0191271,-0.02374817,0.09816021,0.01697672,-0.00496209,-0.00431943,-0.07079358,0.00679333,0.03271287,-0.04963957,0.00449548,0.04598892,-0.03720491,0.01627514,0.06882065,0.00342016,0.02407306,0.03171938,0.05044501,0.07581249,0.01916675,0.01168993,0.01570908,-0.07019786,-0.03444865,-0.2275372,-0.09074551,0.02232313,-0.02213384,0.06145151,-0.06635043,-0.01873842,-0.00874149,0.01378714,0.085526,0.03168834,0.01557545,-0.01636178,-0.02532154,0.00335469,0.0523446,-0.01305151,-0.01177391,-0.04245597,-0.01369699,-0.02306945,0.02001865,0.00764526,-0.09114765,0.01287381,0.00728425,0.12133459,-0.01198924,0.11313121,0.00671269,0.00167004,0.01626778,0.02206787,0.08647305,0.06307527,0.06297016,0.0080341,0.00589606,0.01754797,-0.06425457,0.00007389,0.03349142,0.03858146,-0.02920166,-0.09317565,0.00814138,-0.07629853,-0.00212331,-0.05622058,0.08218168,0.10642539,0.00854912,0.07448816,-0.00350538,0.03873629,-0.04442992,-0.05538114,-0.03902888,-0.03823631,0.01905176,-0.02687961,-0.05487585,-0.00618388,-0.09411359,0.09526792,-0.02690589,-0.00151121,-0.04220649,-0.02354852,-0.0344018,0.00542891,0.09085787,-0.01308036,-0.00488635,0.03342659,0.01359711,-0.01425421,-0.00894561,-0.09006874,-0.01508647,0.04224592,-0.10258897,0.04676552,0.01506603,0.0654175,0.02143762,0.04547295,-0.03192356,-0.00229033,0.00005707,-0.07392168,-0.06223444,0.01576991,-0.03226764,0.02722559,-0.03771603,-0.24258028,-0.01394747,-0.0008021,0.05495191,-0.03869201,0.03011317,0.00799969,0.01694078,-0.03772995,0.00619763,0.01373548,0.02406132,0.04451638,0.00823455,0.04773623,0.01135856,0.00430938,-0.06032327,0.06331827,0.01441252,0.05249931,0.04567878,0.16642357,-0.03445242,0.0708386,0.03951334,-0.05106502,0.01180709,0.08058541,-0.00957466,0.04930554,0.01250349,0.11130629,-0.05391901,0.0480013,0.03652668,0.00481779,0.00409105,0.05078099,-0.09346429,0.03260389,0.018989,0.02035184,0.00004968,0.1502129,0.01284643,-0.04865049,-0.05065425,-0.03150267,0.04480997,-0.0245698,0.07093512,0.04800741,-0.02115504,0.00455568,0.05501656,-0.01099896,-0.04290766,-0.01013952,-0.05908709,0.04225666,-0.03332644,0.04069171,-0.0476363,-0.0792627],"last_embed":{"hash":"hqvp5e","tokens":121}}},"text":null,"length":0,"last_read":{"hash":"hqvp5e","at":1768089430154},"key":"Log Loss Function in NN Model for Multiple Traning Example.md###**2. Intuition Behind the Loss Function**#**Loss When $y = 0$: $L = -\\log(1 - a)$**","lines":[40,45],"size":236,"outlinks":[],"class_name":"SmartBlock","last_embed":{"hash":"hqvp5e","at":1768089430154}},
