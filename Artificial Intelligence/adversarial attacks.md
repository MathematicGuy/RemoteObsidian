**"a type of cyber attack that manipulate machine learning models to produce incorrect results"**

**2 types:**
+ **evasion attacks** (modifying an image so an AI fails to recognize it correctly) 
	
+ **poisoning attacks** (altering the training data to compromise the model's integrity


**e.g.** disrupt model prediction capabilities by **adding small changes in the model's training or testing phrases.**
![[adversarial_example.png]]
**visualize:**
![[electronics-13-02566-g001-550.webp]]
![[image1.png]]